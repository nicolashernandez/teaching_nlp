{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolashernandez/teaching_nlp/blob/main/M2-ATAL-2021-22_02_Machine_Learning_by_feature_engineering_Use_case_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pUMMqbLw3g0"
      },
      "source": [
        "---\n",
        "# Objectifs\n",
        "\n",
        "* Vérifier les comparatifs de performance des systèmes états de l'art (**spaCy, Stanza, trankit**) en reconnaissance d'entités nommées (PER, LOC, ORG et MISC) en les testant sur de nouvelles données (**WiNER**) \n",
        "* Tenter de faire mieux avec l'agorithme d'apprentissage supervisée qui était l'état de l'art des approches statistiques à savoir les _Conditional Random Fields_ ou **CRF**s. Cet algorithme requiert que l'on indique à l'algorithme d'apprentissage les traits à observer dans la donnée. On utilisera le même corpus d'entraînement que les systèmes état de l'art disponibles à savoir **Wikiner**. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAZNCT_Y4RJl"
      },
      "source": [
        "---\n",
        "# Installation\n",
        "\n",
        "Ne pas oublier de redémarrer l'environnement d'exécution après exécution du code ci-dessous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3mNTgir0dsf"
      },
      "outputs": [],
      "source": [
        "# récupération du modèle spaCy \"small\" pour les traitements linguistiques du français\n",
        "# ne pas oublier de redémarrer l'environnement d'exécution\n",
        "!python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx8jR44x6swV"
      },
      "outputs": [],
      "source": [
        "# installation de stanza\n",
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agGfNkhgS-JU"
      },
      "outputs": [],
      "source": [
        "# retrieve a list of french stop words \n",
        "# \"ça peut toujours servir...\"\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "fr_stop_words = nltk.corpus.stopwords.words('french')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq8ZNkaFYvPt"
      },
      "outputs": [],
      "source": [
        "# utilities \n",
        "\n",
        "def flatten(t):\n",
        "  # applatie une liste de listes en une unique liste... \n",
        "  # [[a, b], [c], [d, e, f]] -> [a, b, c, d, e, f]\n",
        "  return [item for sublist in t for item in sublist]\n",
        "\n",
        "import re \n",
        "def normalise_labels(sentences):\n",
        "  # normalise les sorties des étiquettes NER utilisées par les différents \n",
        "  # systèmes afin de les rendre comparable\n",
        "  new_sentences = list()\n",
        "  for sentence in sentences:\n",
        "    new_sentence = list()\n",
        "    for label in sentence:\n",
        "      if label != 'O':\n",
        "        label = re.sub('^[A-Z]-','', label)\n",
        "      new_sentence.append(label)\n",
        "    new_sentences.append(new_sentence)\n",
        "  return new_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Introduction : La reconnaissance d'Entités Nommées\n",
        "\n",
        "\n",
        "\n",
        "> _We’ll use the term **named entity** for, roughly speaking, anything that can be referred to with a named entity proper name: a person, a location, an organization, although as we’ll see the term is commonly extended to include things that aren’t entities per se._ \n",
        " [Chapter 8 - Sequence Labeling for parts of speech and named entities. In Speech and Language Processing. Daniel Jurafsky & James H. Martin. Draft of September 21, 2021.](https://web.stanford.edu/~jurafsky/slp3/8.pdf)\n",
        "\n",
        "La tâche de reconnaissance d'EN n'est pas une tâche de classification comme les autres où pour chaque instance il s'agit d'assigner la bonne classe. Dans une tâche de reconnaissance d'EN, il faut à la fois délimitter les mots qui composent l'instance et assigner l'étiquette à cette instance. Une astuce a été proposée pour se ramener au premier type de problème : il s'agit de considérer les mots commes des instances et de spécifier les étiquettes avec des préfixes pour désigner si le mot courant _Begin_ une NE, si il est _Inside_ une NE ou bien _Outside_. Voir le [format BIO](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)).\n",
        "\n",
        "Ainsi la tâche de **Reconnaissance d'Entités Nommées** (en anglais _Named Entity Recognition_ ou _NER_) consiste à assigner aux mots des étiquettes comme PER(SON), LOC(ATION), or ORG(ANIZATION). Une tâche dans laquelle on assigne pour chaque mot `x_i` d'une séquence de mots en entrée, une étiquette (_label_ en anglais) `y_i`, de telle façon que la séquence `Y` en sortie a la même longueur que la séquence `X` en entrée est appellée **tâche d'étiquetage de séquence** (_sequence labeling task_ en anglais). \n",
        "Parmi les algorithmes classiques qui capturent les dépendances entre les mots on liste le _Hidden Markov Model (HMM)_, le _Conditional Random Field (CRF)_. \n",
        "\n",
        "Par la suite, nous nous intéresserons aux EN les plus classiques à savoir les types LOC, ORG, PER, aussi appelées _enamex_ depuis la 6e compétition des _Message Understanding Conferences (MUC-6)_. Cf.\n",
        "[Grishman, Ralph; Sundheim, Beth (1996). Design of the MUC-6 evaluation (PDF). TIPSTER '96 Proceedings](https://dl.acm.org/doi/10.3115/1119018.1119072). \n",
        "Nous considérerons le type _MISC(ELLANEOUS)_ utilisé dans les conférences [CONLL](https://www.conll.org/) qui inclut les noms propres autres que les classiques _enamex_.\n",
        "\n",
        "Pour un revue et définition des types d'EN cf. [Nadeau, David; Sekine, Satoshi (2007). A survey of named entity recognition and classification (PDF). Lingvisticae Investigationes](https://nlp.cs.nyu.edu/sekine/papers/li07.pdf).\n",
        "\n",
        "Les données que nous manipulerons ont été pré-traités pour tokeniser les textes et normaliser les jeux d'étiquettes des NE et des POS (part of speech).\n",
        "\n",
        "Référez vous au notebook précédent pour les présentations de spaCy, Stanza et Trankit."
      ],
      "metadata": {
        "id": "0JXP4q4y_VFJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKCTdrbWLpCF"
      },
      "source": [
        "# Protocole d'évaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s6lRJNstx0d"
      },
      "source": [
        "## WiNER, données de développement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxSGvi2GuuDm"
      },
      "source": [
        "[WiNER](https://github.com/YoannDupont/WiNER-fr) is a free corpus for Named Entity Recognition based on Wikinews texts.\n",
        "\n",
        "The current named entity tagset is:\n",
        "* Date (absolute dates.)\n",
        "* Event (conferences, sports events, annual events, celebration days, named climatic events, etc.)\n",
        "*  Hour (absolute hours. If present, they include time zones, UTC, GMT, etc.)\n",
        "* Location (countries, towns, regions, addresses, astophysicals objects, hydrophysical objects, etc.)\n",
        "* Organization (non profit organizations, companies, medias, etc.)\n",
        "* Person (human individuals, without their title or function. They can be actual people or fictional characters.)\n",
        "* Product (physical objects, brands, softwares.)\n",
        "\n",
        "The tagset was defined using various campaigns or resources: MUC-6, CoNLL-2003, Named Entity annotated French Treebank and Quaero. Every type defined in this tagset is directly taken from one of those.\n",
        "\n",
        "> Yoann Dupont. Un corpus libre, évolutif et versionné en entités nommées du français. TALN 2019 - Traitement Automatique des Langues Naturelles, Jul 2019, Toulouse, France. \n",
        "https://hal.archives-ouvertes.fr/hal-02448590\n",
        "\n",
        "Le format de stockage original utilisé pour représenter les annotations est de type **_stand off annotation_**. _standoff_ désigne les formats où les annotations sont stockées séparément du contenu annoté, lequel n’est jamais modifié par l'outil annotateur. Pour déterminer à quel contenu annoté, une annotation est rattachée, on accompagne les annotations d'offsets (indice de caractères de début et de fin) du contenu annoté ou d'indices de tokens du contenu annoté. La lecture de ces formats par un humain n’est pas forcément aisée, leur manipulation (édition et visualisation) requiert des développements spécifiques. Néanmoins ces formats présentent l’intérêt de gérer la concurrence entre annotations (e.g. des annotations qui se recouvrent partiellement ou de même type mais de fournisseurs différents), de ne pas être contraint par la nature de l’information ajoutée (span, relation, ...) et surtout de ne perdre aucune information du document original (ne serait ce que sa mise en forme). \n",
        "\n",
        "Ici un [exemple de texte extrait du corpus](https://github.com/YoannDupont/WiNER-fr/blob/master/2016/01/2016_01_01-001.txt) et son [fichier associé qui contient les annotations \"standoff\"](https://github.com/YoannDupont/WiNER-fr/blob/master/2016/01/2016_01_01-001.ann).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h68O1gwaNTk2"
      },
      "source": [
        "### QUESTION\n",
        "\n",
        "* Le corpus WiNER, tel qu'il est téléchargeable sur le site de son fournisseur, utilise-t-il des offsets ou des indices de tokens ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA7UyIc7NXT0"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV3uLpyBSX3p"
      },
      "source": [
        "### Récupération et préparation des données\n",
        "\n",
        "Pour les besoins de ce travail, nous utiliserons un extrait du corpus, tokenisé par spaCy, avec les annotations projetées sur les tokens. \n",
        "\n",
        "Ce sont les types LOC, ORG, PER et MISC qui nous intéresseront.\n",
        "\n",
        "Le type _Location_ a été renommé en _LOC_, _Organization_ en _ORG_, _Person_ en _PER_. Stanza et spaCy reconnaissent aussi des entités de type MISC. Sans vraiment chercher ce qu'elle désigne, nous avons pris le partie de renommer _Product_ en _MISC_. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmkLTqsMurqN"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data\n",
        "!wget -nc https://github.com/nicolashernandez/teaching_nlp/raw/main/data/winer_dev.joblib -P data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVOnQ4r7t-Ht"
      },
      "outputs": [],
      "source": [
        "# load the test corpus\n",
        "from joblib import load\n",
        "winer_corpus = load('data/winer_dev.joblib')\n",
        "\n",
        "# get the tokens of each text\n",
        "winer_ref = [[label for token, pos, label in text] for text in winer_corpus]\n",
        "labels = list(set(flatten(winer_ref)))\n",
        "winer_tokens = [[token for token, pos, label in text] for text in winer_corpus]\n",
        "\n",
        "#\n",
        "print ('#texts:', len(winer_corpus))\n",
        "print ('labels:', labels)\n",
        "\n",
        "print ('sample of annotated texts:', winer_corpus[0])   \n",
        "print ('sample of tokenized text:', winer_tokens[0])   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmsI84MBw3g2"
      },
      "source": [
        "## Métriques d'évaluation\n",
        "\n",
        "La reconnaissance des entités nommées est un problème de classification multi-classes. On peut donc utiliser toutes les mesures de classification. En général, on privilégie la **micro-moyenne de scores F1** (_micro-averaged F1_) qui combine précision et rappel.\n",
        "\n",
        "La micro-moyenne d'une métrique aggrège d'abord les contributions de toutes les classes avant de calculer la métrique tandis que la macro-moyenne calcule la métrique indépendamment pour chaque classe puis en fait la moyenne. \n",
        "\n",
        "La macro-moyenne traite toutes les classes de manière égale. \n",
        "Dans le cas où le système n'est bon que pour reconnaître une classe (la classe dominante), la micro-moyenne peut être élevée car les contributions des autres classes seront insignifiantes. Dans ce cas, la macro-moyenne sera basse.\n",
        "\n",
        "Dans le cas où le système n'est mauvais que pour la reconnaissance d'une seule classe, la macro-moyenne gommera son effet. La micro-moyenne peut être élevée même si le système donne de mauvais résultat sur des classes rares, car il donne plus de poids aux classes communes.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7ZBrBrjw3g2"
      },
      "outputs": [],
      "source": [
        "# Measures definition\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def results_per_class(labels, y_ref, y_hyp):\n",
        "  # Inspect per-class results in more detail:\n",
        "  sorted_labels = sorted(\n",
        "    labels,\n",
        "    key=lambda name: (name[1:], name[0])\n",
        "  )\n",
        "  # print ('y_ref', len(y_ref), 'y_hyp', len(y_hyp), 'sorted_labels', len(sorted_labels))\n",
        "  return classification_report(flatten(y_ref), flatten(y_hyp), labels=sorted_labels, digits=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5594hie-zr3"
      },
      "outputs": [],
      "source": [
        "# Il y a beaucoup plus d'entités 'O' que les autres dans le corpus, \n",
        "# mais nous sommes davantage intéressés par les autres entités. \n",
        "# Pour ne pas biaiser les scores de moyenne, on retire les étiquettes qui ne nous intéressent pas.\n",
        "print (\"before removing:\", labels)\n",
        "labels_to_remove = ['O', 'Event', 'Date', 'Hour']\n",
        "for l in labels_to_remove:\n",
        "  if l in labels:\n",
        "    labels.remove(l)\n",
        "print (\"after removing:\", labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jciW0FC0XY3"
      },
      "source": [
        "---\n",
        "# Prédiction et évaluation de spaCy\n",
        "\n",
        "Avant tout autre traitement linguistique, spaCy tokenize les textes donnés en entrée (et segmente en phrases aussi). Néanmoins quand les textes ont déjà été tokenisés ou bien pour appliquer spaCy sur une tokenization produite par un autre outil, il est possible de fournir en entrée de spaCy des textes où la tokenization est marquée par un espace et d'indiquer au moteur de spaCy d'utiliser un tokenizer fondé sur les espaces..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW6stvcd92xZ"
      },
      "source": [
        "## Construction de la chaîne de traitements\n",
        "\n",
        "Création d'un moteur `spacy_nlp` qui traite le français (entre autres qui reconnait les entités nommées) et tokenize d'abord sur les espaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDoSAIMI0cM-"
      },
      "outputs": [],
      "source": [
        "# Create my whitespace tokenizer\n",
        "#\n",
        "# one trick to make spaCy consider a tokenization performed by a third-party component: \n",
        "# use whitespace as separator for marking the third-party component tokenization \n",
        "# and force spacy to use a whitespace tokenizer...\n",
        "\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "class WhitespaceTokenizer(object):\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __call__(self, text):\n",
        "        words = text.split(' ')\n",
        "        # All tokens 'own' a subsequent space character in this tokenizer\n",
        "        spaces = [True] * len(words)\n",
        "        return Doc(self.vocab, words=words, spaces=spaces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkZjR_jx0zfj"
      },
      "outputs": [],
      "source": [
        "# Build a spacy nlp pipeline with a ner model and the whitespace tokenizer\n",
        "\n",
        "import spacy\n",
        "\n",
        "# load a nlp model\n",
        "spacy_nlp = spacy.load(\"fr_core_news_sm\")\n",
        "\n",
        "# declare the whitespace tokenizer\n",
        "spacy_nlp.tokenizer = WhitespaceTokenizer(spacy_nlp.vocab)\n",
        "\n",
        "#\n",
        "#print ('nlp pipeline='+str([name for (name, proc) in spacy_nlp.pipeline]))\n",
        "# pipeline['tagger', 'parser', 'ner']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccywkwCC-Avd"
      },
      "source": [
        "## Prédiction\n",
        "\n",
        "Pour chaque phrase de WiNER, on applique spaCy et on stoque les étiquettes NE prédites pour chaque mot de chaque phrase dans un tableau, appelé hypothèse de spaCy `spacy_hyp`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQlf8y1V06Hi"
      },
      "outputs": [],
      "source": [
        "# Run spacy nlp pipeline made of ner component and evaluate it\n",
        "# CPU --- 13.573408365249634 seconds ---\n",
        "# GPU --- 10.968162775039673 seconds ---\n",
        "\n",
        "#\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "spacy_hyp = []\n",
        "# pour chaque phrase de wikiner\n",
        "for text in winer_tokens:\n",
        "    # à la volée on désactive les analyseurs syntaxiques pour gagner en rapidité\n",
        "    # tokenize et appliquer le modèle de reconnaissance des EN embarqué dans le modèle\n",
        "    doc = spacy_nlp(' '.join(text), disable=[\"tagger\", \"parser\"])\n",
        "    #print (doc)\n",
        "    spacy_hyp.append([(token.ent_iob_+'-'+token.ent_type_) for token in doc])\n",
        "    #break\n",
        "\n",
        "#\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "# normalize the hyp labels\n",
        "normalized_spacy_hyp = normalise_labels(spacy_hyp)\n",
        "#print (winer_tokens[0])\n",
        "#print (winer_ref[0])\n",
        "#print (spacy_hyp[0])\n",
        "#print (normalized_spacy_hyp[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAbKPlCh-Ulm"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "On compare l'hypothèse de spaCy avec la référence. On fournit les étiquettes que l'on souhaite considérer dans le calcul des mesures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE8b56iSw3g3"
      },
      "outputs": [],
      "source": [
        "# Evaluate on data \n",
        "print (results_per_class(labels, winer_ref, normalized_spacy_hyp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIMf-oRE-sEf"
      },
      "source": [
        "### QUESTION\n",
        "\n",
        "La colonne _support_ indique le nombre d'instances par classe. \n",
        "\n",
        "* Le f1-score de la classe _MISC_ est très mauvais. Pour rappel, la classe MISC à reconnaître dans le corpus WiNER correspond à sa classe Product que nous avons renommé. Pour rappel encore, spaCy a été entraîné avec le corpus Wikiner. En vous rapportant à la définition de la classe Product du [corpus WiNER](https://github.com/YoannDupont/WiNER-fr) et en la comparant avec la définition de la classe MISC du [corpus Wikiner](https://www.sciencedirect.com/science/article/pii/S0004370212000276?via%3Dihub\n",
        "), émettez une hypothèse qui puisse expliquer la mauvaise qualité des résultats.  \n",
        "* Retirez la classe MISC du décompte ou bien vérifiez votre hypothèse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snAo20GS-vZM"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GylZoaI6kql"
      },
      "source": [
        "---\n",
        "# Prédiction et évaluation de Stanza\n",
        "\n",
        "Ci-dessous le code qui permet de construire un moteur Stanza de traitements linguistiques du français. La prédiction est beaucoup lente que spaCy. Vous pouvez tester son temps de traitement avec une copie du notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAmH3zkQ98eW"
      },
      "source": [
        "## Construction de la chaîne de traitements\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge9GGh1P6lTu"
      },
      "outputs": [],
      "source": [
        "# Build a stanza nlp pipeline with a ner model and the whitespace tokenizer\n",
        "\n",
        "import stanza\n",
        "\n",
        "# download French model\n",
        "stanza.download('fr') \n",
        "\n",
        "# https://stanfordnlp.github.io/stanza/tokenize.html#start-with-pretokenized-text \n",
        "# pretokenized (and sentence split) text correspond to use newline (\\n) to separated sentences and each sentence is space separated tokens\n",
        "stanza_nlp = stanza.Pipeline('fr', processors='tokenize,ner', tokenize_pretokenized=True) # initialize French neural pipeline\n",
        "\n",
        "# run on sample \n",
        "#doc = stanza_nlp(\"Barack Obama est né à Hawaii .\") # run annotation over a sentence\n",
        "#print(doc)\n",
        "#print(doc.entities)\n",
        "#print(*[f'token: {token.text}\\tner: {token.ner}' for sent in doc.sentences for token in sent.tokens], sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpzcULpG-Ms_"
      },
      "source": [
        "## Prédiction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxTBxlqB693N"
      },
      "outputs": [],
      "source": [
        "# Running stanza nlp pipeline made of ner component and evaluate it\n",
        "# CPU --- 1848.740861415863 seconds ---\n",
        "# GPU --- 311.1391832828522 seconds ---\n",
        "\n",
        "#\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# \n",
        "stanza_hyp = []\n",
        "for text in winer_tokens:\n",
        "    doc = stanza_nlp(' '.join(text))\n",
        "    stanza_hyp.append([token.ner for sent in doc.sentences for token in sent.tokens])\n",
        "\n",
        "#\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "# normalize the hyp labels\n",
        "normalized_stanza_hyp = normalise_labels(stanza_hyp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsSvpgly-Qjl"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSFOS1zO-bI1"
      },
      "outputs": [],
      "source": [
        "# Evaluate on data \n",
        "print (results_per_class(labels, winer_ref, normalized_stanza_hyp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uRvRT2zJosj"
      },
      "source": [
        "### QUESTION\n",
        "\n",
        "Le type d'exécution par défaut de Google Colab utilise un CPU pour les calculs.\n",
        "* En termes de rapidité de traitement, quel est le meilleur des deux systèmes spaCy ou Stanza ? \n",
        "* Pouvez-vous donner une idée du nombre de mots traités à la seconde ? Cette dernière question requiert quelques lignes de codes ; vous pouvez vous restreindre à quelques phrases poru votre estimation.\n",
        "* Il vous est possible de changer de type d'exécution et passer à un type GPU. Cela accélèrera les entraînements comme les prédictions des modèles. Pour ce faire, `Exécution > Modifier le type d'exécution > GPU`. Il vous faudra ensuite exécuter à nouveau tout le code. Attention à ne pas utiliser inutillement cette ressource. Le rapport a t-il changé ? Le gain est-il probant ?\n",
        "* En termes de qualité de traitement, quel est le meilleur des deux systèmes spaCy ou Stanza ?\n",
        "* Est-ce que ces observations correspondent à ce qui est relevé sur le [comparatif de performance du site de spaCy](https://spacy.io/usage/facts-figures) ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIhEI6hUJzPY"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iKbv3kOK6I8"
      },
      "source": [
        "---\n",
        "# Prédiction et évaluation de trankit\n",
        "\n",
        "Pour rappel, Trankit _is a light-weight Transformer-based Python Toolkit for multilingual Natural Language Processing (NLP). The v1.0.0 has pretrained pipelines using XLM-Roberta Large. The pipeline obtains competitive or better named entity recognition (NER) performance compared to existing popular toolkits on 11 public NER datasets over 8 languages._\n",
        "\n",
        "> [Nguyen, Minh Van and Lai, Viet and Veyseh, Amir Pouran Ben and Nguyen, Thien Huu, Trankit: A Light-Weight Transformer-based Toolkit for Multilingual Natural Language Processing, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations, 2021](https://arxiv.org/pdf/2101.03289.pdf)\n",
        "\n",
        "* Consignes d'installation https://trankit.readthedocs.io/en/latest/installation.html\n",
        "* Consignes d'exécution d'un ner https://trankit.readthedocs.io/en/latest/ner.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyuOX4G4LVhh"
      },
      "source": [
        "### QUESTION\n",
        "\n",
        "La question suivante sera a traité en fonction de votre avancement et des consignes données par votre encadrant. Posez lui la question.\n",
        "\n",
        "* Votre travail est d'installer et de mettre en oeuvre trankit pour évaluer sa performance sur le corpus WiNER. Suivre les consignes TODO ci-dessous.\n",
        "* Que pouvez-vous des performances de trankit comparativement aux autres systèmes ?\n",
        "* trankit peut traiter une phrase ou une liste de phrases. Quelle précaution dois-je prendre dans ce second cas ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st4ZbzGZLUkq"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poN4cxyMLPkw"
      },
      "source": [
        "## Construction de la chaîne de traitements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEqGwUYeLB4R"
      },
      "outputs": [],
      "source": [
        "# TODO installation des modules pip requis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72lOav5JLKwJ"
      },
      "outputs": [],
      "source": [
        "# TODO construction de la pipeline trankit_nlp à partir d'un modèle français\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prédiction"
      ],
      "metadata": {
        "id": "dm_RfI60W1T2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_mtr20LNVqU"
      },
      "outputs": [],
      "source": [
        "# Running trankit nlp pipeline made of ner component and evaluate it\n",
        "# CPU\n",
        "# GPU --- 162.0407838821411 seconds ---\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "trankit_hyp = []\n",
        "# TODO appliquer trankit_nlp à chaque phrase tokenisée et récupérer les étiquettes de chaque mot de chaque phrase dans stanza_hyp\n",
        "for text in winer_tokens:\n",
        "    print ('TODO')\n",
        "\n",
        "#\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WpFpASJgEgK"
      },
      "outputs": [],
      "source": [
        "# normalize the hyp labels\n",
        "normalized_trankit_hyp = normalise_labels(trankit_hyp)\n",
        "\n",
        "# evaluate on data \n",
        "print (results_per_class(labels, winer_ref, normalized_trankit_hyp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9xUDe1jAF5q"
      },
      "source": [
        "---\n",
        "# Construction d'un système NER selon une approche supervisée CRF à base de traits \n",
        "\n",
        "L'algorithme des _Conditional random fields_ est décrit dans l'article suivant : \n",
        "> [Conditional random fields: Probabilistic models for segmenting and labeling sequence data, Lafferty, J., McCallum, A., Pereira, F., Proc. 18th International Conf. on Machine Learning, Morgan Kaufmann, p. 282–289, 2001](https://people.cs.umass.edu/~mccallum/papers/crf-tutorial.pdf)\n",
        "\n",
        "De manière simplifiée, le modèle apprend à prédire la séquence d'étiquettes _statistiquement_ la plus probable donnée une séquence de mots. En pratique, un mot est représenté par un ensemble de traits tels que sa forme de surface, son étiquette grammaticale, son suffixe, le fait qu'il débute par une majuscule, des traits du mot qui le précède... \n",
        "\n",
        "De manière plus formelle, un [CRF (section 8.5)](https://web.stanford.edu/~jurafsky/slp3/8.pdf) est un modèle log-linéaire qui assigne une probabilité à une entière séquence d'étiquettes Y, donnée une séquence de mots X. La fonction [log-linéaire](https://en.wikipedia.org/wiki/Log-linear_model) est une fonction qui retourne le logarithme d'une combinaison linéaire de différents paramètres ; chacun des paramètres correspondant à la somme d'un type trait de la séquence de mots considérés. Cette fonction, log-linéaire, permet d'appliquer une [régression linéaire multiple](https://en.wikipedia.org/wiki/Linear_regression) qui permet de modéliser les relations entre des scalaires (les valeurs des traits) et des variables (les étiquettes).\n",
        "L'entraînement vise à apprendre au modèle à \"_discriminer_\" parmis toutes les séquences possibles.\n",
        "\n",
        "Les cellules ci-dessous implémentent une solution de bout en bout pour\n",
        "- entraîner un modèle de prédiction à partir des données d'entraînement Wikiner; \n",
        "- appliquer le modèle construit pour la prédiction d'entités nommées sur le corpus de dev WiNER;\n",
        "- évaluer les résultats.\n",
        "\n",
        "Avant de la mettre en oeuvre, lisez la suite.\n",
        "\n",
        "Dans une méthode d'apprentissage supervisée à base de traits, c'est au \"scientifique\" ou \"ingénieur de la donnée\" de définir et d'implémenter les traits à observer dans la donnée et à donner en entrée du système d'apprentissage.\n",
        "\n",
        "Les premières cellules de code ci-dessous proposent une implémentation d'une méthode d'extraction de traits du mot courant à savoir la méthode `word2features`.\n",
        "Cette méthode doit être appelées aussi bien sur les données d'entraînement que sur les données où l'on cherche à appliquer un modèle construit pour obtenir une prédiction. Cette méthode est à la base de la construction de la représentation des mots et donc de la séquence de mots que traite l'algo de prédiction.\n",
        "\n",
        "Nous utiliserons l'implémentation `sklearn_crfsuite.CRF` qui globalement suit l'API sklearn. Nous suivrons la démarche décrite dans le tutoriel de l'implémentation [sklearn-crfsuite](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html).\n",
        "L'optimisation des paramètres est possible (cf. le tutoriel).\n",
        "\n",
        "Poursuivez votre lecture mais sachez que le système fonctionne en l'état."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNyQNZ48w3go"
      },
      "source": [
        "## Wikiner, données d'entraînement\n",
        "\n",
        "Pour entraîner notre système, nous allons utiliser les mêmes données d'entraînement de que les composants NER de spaCy ou Stanza à savoir les données du corpus Wikiner.\n",
        "\n",
        "```\n",
        "@Article{nothman2012:artint:wikiner,\n",
        "  author = {Joel Nothman and Nicky Ringland and Will Radford and Tara Murphy and James R. Curran},\n",
        "  title = {Learning multilingual named entity recognition from {Wikipedia}},\n",
        "  journal = {Artificial Intelligence},\n",
        "  publisher = {Elsevier},\n",
        "  volume = {194},\n",
        "  pages = {151--175},\n",
        "  year = {2012},\n",
        "  doi = {10.1016/j.artint.2012.03.006},\n",
        "  url = {http://dx.doi.org/10.1016/j.artint.2012.03.006}\n",
        "}\n",
        "```\n",
        "https://www.sciencedirect.com/science/article/pii/S0004370212000276?via%3Dihub\n",
        "\n",
        "Les données utilisées proviennent de l'annotation \"silver standard\" du [corpus Wikiner généré à partir de la Wikipedia et téléchargeable ici](https://github.com/dice-group/FOX/tree/master/input/Wikiner). \n",
        "\n",
        "Le pos tagging a été modifié pour adopter le système d'étiquettes de l'[universal dependencies (UD)](https://universaldependencies.org/u/pos/) (grâce à spaCy).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv9TkbDxw3gp"
      },
      "outputs": [],
      "source": [
        "# Getting the data\n",
        "!mkdir -p data \n",
        "!wget -nc https://github.com/nicolashernandez/teaching_nlp/raw/main/data/wikiner_ud.joblib.bz2 -P data\n",
        "!bzip2 -dk data/wikiner_ud.joblib.bz2\n",
        "\n",
        "# Loading the corpus \n",
        "from joblib import load\n",
        "wikiner_corpus = load('data/wikiner_ud.joblib') \n",
        "\n",
        "\n",
        "# Aperçu du nombre de phrases et d'une phrase annotée (liste de tokens composés de la forme, de la catégorie grammaticale et de l'étiquette BIO correspondant en l'entité nommée.\n",
        "print (len(wikiner_corpus))\n",
        "print (wikiner_corpus[0])  \n",
        "# [('Il', 'PRO:PER', 'O'), ('assure', 'VER:pres', 'O'), ('à', 'VER:pper', 'O'), ('la', 'DET:ART', 'O'), ('suite', 'NOM', 'O'), ('de', 'PRP', 'I-PER'), ('Saussure', 'NAM', 'I-PER'), ('le', 'DET:ART', 'O'), ('cours', 'NOM', 'O'), ('de', 'PRP', 'O'), ('grammaire', 'NOM', 'O'), ('comparée', 'ADJ', 'O'), (',', 'PUN', 'O'), (\"qu'\", 'PRO:REL', 'O'), ('il', 'PRO:PER', 'O'), ('complète', 'VER:subp', 'O'), ('à', 'VER:pper', 'O'), ('partir', 'VER:infi', 'O'), ('de', 'PRP', 'O'), ('1894', 'NUM', 'O'), ('par', 'PRP', 'O'), ('une', 'DET:ART', 'O'), ('conférence', 'NOM', 'O'), ('sur', 'PRP', 'O'), (\"l'\", 'DET:ART', 'O'), ('iranien', 'ADJ', 'O'), ('.', 'SENT', 'O')]\n",
        "# [('Il', 'PRON', 'O'), ('assure', 'VERB', 'O'), ('à', 'ADP', 'O'), ('la', 'DET', 'O'), ('suite', 'NOUN', 'O'), ('de', 'ADP', 'I-PER'), ('Saussure', 'NOUN', 'I-PER'), ('le', 'DET', 'O'), ('cours', 'NOUN', 'O'), ('de', 'ADP', 'O'), ('grammaire', 'ADJ', 'O'), ('comparée', 'VERB', 'O'), (',', 'PUNCT', 'O'), (\"qu'\", 'SCONJ', 'O'), ('il', 'PRON', 'O'), ('complète', 'VERB', 'O'), ('à', 'ADP', 'O'), ('partir', 'VERB', 'O'), ('de', 'ADP', 'O'), ('1894', 'NUM', 'O'), ('par', 'ADP', 'O'), ('une', 'DET', 'O'), ('conférence', 'NOUN', 'O'), ('sur', 'ADP', 'O'), (\"l'\", 'DET', 'O'), ('iranien', 'NOUN', 'O'), ('.', 'PUNCT', 'O')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7HiiQNu4Vcd"
      },
      "source": [
        "Dans la cellule ci-dessous vous pouvez spécifier la quantité de données du corpus que vous souhaitez utiliser pour votre entraînement. En l'état, il est spécifié 10% pour faire des tests fonctionnels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aM9jylsK4Sqf"
      },
      "outputs": [],
      "source": [
        "# shuffle the data\n",
        "#from random import shuffle\n",
        "#shuffle(wikiner_corpus)\n",
        "\n",
        "print ('len(wikiner_corpus):', len(wikiner_corpus))\n",
        "\n",
        "\n",
        "# compute corpus partition sizes \n",
        "_100_percent = int(len(wikiner_corpus)/100*100)\n",
        "\n",
        "_80_percent = int(len(wikiner_corpus)/100*80)\n",
        "_50_percent = int(len(wikiner_corpus)/100*50)\n",
        "_10_percent = int(len(wikiner_corpus)/100*10)\n",
        "\n",
        "# TODO ICI vous pouvez choisir la quantité de données \n",
        "# 10 % vous permet de faire des tests fonctionnels mais le modèle qui sera entraîné sera pauvre\n",
        "train_sentences = wikiner_corpus[:_10_percent]\n",
        "print ('len(train_sentences):', len(train_sentences))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hd6EG-4AHl9"
      },
      "source": [
        "## Extraction des caractéristiques\n",
        "\n",
        "Ci-dessous vous trouverez la méthode `word2features` qui se charge de transformer les mots en traits que prendra l'algorithme d'apprentissage en entrée pour la construction du modèle. Remarquez que les phrases pour lesquelles il faudra faire une prédiction devront aussi passer par ce traitement. \n",
        "La méthode prend en paramètre une phrase (i.e. une liste de mots) et un indice correspondant au mot pour lequel il faut générer des traits.\n",
        "\n",
        "A toutes fins utiles, voici quelques pointeurs qui décrivent les traits utilisés dans la littérature pour décrire les mots à des fin de NER\n",
        "* Table \"2\" de [J. R. Finkel, T. Grenager, and C. Manning. 2005. Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling. Proceedings of ACL](https://nlp.stanford.edu/~manning/papers/gibbscrf3.pdf)\n",
        "* Section \"4.2.1 Spelling features\" de [Zhiheng Huang, Wei Xu, Kai Yu, Bidirectional LSTM-CRF Models for Sequence Tagging, Arxiv, Computation and Language, Submitted on 9 Aug 2015](https://arxiv.org/pdf/1508.01991.pdf) (premier article à appliquer les BiLSTM-CRF au NER)\n",
        "* Implémentation des [traits pour le NER](https://github.com/Jekub/Wapiti/blob/master/dat/nppattern.txt) dans [Wapiti](https://wapiti.limsi.fr/), un des outils les plus performants en 2013... pour faire du \"sequence labeling\" à l'aide des CRF, avec [explication du formalisme dans la section patterns de la documentation](https://wapiti.limsi.fr/manual.html#patterns)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp9iPdgvVaP6"
      },
      "source": [
        "### QUESTION\n",
        "\n",
        "* Exécutez les différentes cellules jusqu'à l'évaluation. Optez aussi pour un entraînement avec 100 % des données d'entrainement. Les performances produites par les traits disponibles constitueront votre \"baseline\". En attendant que les traitements se terminent (quelques minutes à 100%), répondez aux questions suivantes.\n",
        "* Dans la méthode `word2features`, que signifient `word`, `postag`, `wordminus1`, `postagminus1`, `wordplus1`, `postagplus1` ?\n",
        "* Dans la méthode `word2features`, que signifient les traits `word.lower()`,    `word[-3:]`, `word.isupper()`, `word.istitle()`, `word.isdigit()`, `postag`, `postag[:2]` ?\n",
        "* Reprenez la méthode, ajoutez de nouveaux traits, réécrivez les définitions existantes, votre objectif obtenir le meilleur micro-average f1 score sur WiNER avant le temps imparti et délivrer votre modèle dans le dépôt indiqué par l'enseignant. Expliquer verbeusement les traits que vous implémentez ! La mise au point de votre jeu de traits doit être éprouver dans l'env gcolab avec les ressources limitées (RAM à 12 Go). \n",
        "La [figure 8.15](https://web.stanford.edu/~jurafsky/slp3/8.pdf) liste quelques traits. \n",
        "* Qu'est ce qu'un \"gazetteer\" ?\n",
        "* Comparez vos performances avec votre baseline et avec les systèmes état de l'art, que pouvez-vous conclure ? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlPPa0Uw1POU"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFjwE-hYw3gx"
      },
      "outputs": [],
      "source": [
        "# Features definition\n",
        "#\n",
        "# https://eli5.readthedocs.io/en/latest/tutorials/sklearn_crfsuite.html\n",
        "#\n",
        "# Feature extraction\n",
        "# POS tags can be seen as pre-extracted features. \n",
        "# Let’s extract more features (word parts, simplified POS tags, lower/title/upper flags, features of nearby words) \n",
        "# and convert them to sklear-crfsuite format - each sentence should be converted to a list of dicts. \n",
        "# This is a very simple baseline; you certainly can do better.\n",
        "# https://docs.python.org/3/library/stdtypes.html\n",
        "\n",
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "    }\n",
        "    if i > 0:\n",
        "        wordminus1 = sent[i-1][0]\n",
        "        postagminus1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': wordminus1.lower(),\n",
        "            '-1:word.istitle()': wordminus1.istitle(),\n",
        "            '-1:word.isupper()': wordminus1.isupper(),\n",
        "            '-1:postag': postagminus1,\n",
        "            '-1:postag[:2]': postagminus1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        wordplus1 = sent[i+1][0]\n",
        "        postagplus1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': wordplus1.lower(),\n",
        "            '+1:word.istitle()': wordplus1.istitle(),\n",
        "            '+1:word.isupper()': wordplus1.isupper(),\n",
        "            '+1:postag': postagplus1,\n",
        "            '+1:postag[:2]': postagplus1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KO8RKtRRVDzB"
      },
      "outputs": [],
      "source": [
        "# Features extraction\n",
        "\n",
        "tokens_train = [sent2tokens(s) for s in train_sentences]\n",
        "X_train = [sent2features(s) for s in train_sentences]\n",
        "y_train = normalise_labels([sent2labels(s) for s in train_sentences])\n",
        "\n",
        "print (tokens_train[0])\n",
        "print (X_train[0][0])\n",
        "print (X_train[0][1])\n",
        "print (len(y_train))\n",
        "print (y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex3fq-DEw3g4"
      },
      "source": [
        "## Entraînement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HXREqFMx4Wm"
      },
      "outputs": [],
      "source": [
        "# instanciation du modèle crf et initialisation des hyperparamètres\n",
        "#!pip install sklearn_crfsuite #0.3.6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rs3p96NnWsXk"
      },
      "outputs": [],
      "source": [
        "import sklearn_crfsuite\n",
        "\n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=20,\n",
        "    all_possible_transitions=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndkWV-0KW1P1"
      },
      "outputs": [],
      "source": [
        "# --- 134.15347862243652 seconds ---\n",
        "\n",
        "import time\n",
        "#\n",
        "start_time = time.time()\n",
        "\n",
        "# train\n",
        "crf.fit(X_train, y_train);\n",
        "\n",
        "#\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time)) #  110s - 230s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMvE-ZkkW2q8"
      },
      "outputs": [],
      "source": [
        "# Persistence: model dump\n",
        "!mkdir -p models\n",
        "\n",
        "from joblib import dump\n",
        "dump(crf, 'models/wikiner_sklearn-crfsuite.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG1V8aDlXNJN"
      },
      "source": [
        "## Prédiction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyzzltlHw3g4"
      },
      "outputs": [],
      "source": [
        "# Extract features from the test data and predict \n",
        "winer_dev = [sent2features(s) for s in winer_corpus]\n",
        "\n",
        "crf_hyp = crf.predict(winer_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auOBpjR6XaZk"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eok1LtQriZBk"
      },
      "outputs": [],
      "source": [
        "# Evaluate on data \n",
        "print (results_per_class(labels, winer_ref, crf_hyp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfNyxXecw3g6"
      },
      "source": [
        "## Vérification de ce que le classifieur a appris\n",
        "https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#let-s-check-what-classifier-learned\n",
        "\n",
        "Ce qui suit peut vous donner des idées sur le genre de traits qui peut vous être utiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypRdwFW-w3g6"
      },
      "outputs": [],
      "source": [
        "# quid des transitions d'une étiquette à l'autre ?\n",
        "from collections import Counter\n",
        "\n",
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
        "\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mftyVhMlw3g7"
      },
      "outputs": [],
      "source": [
        "# quid des caractéristiques ? \n",
        "def print_state_features(state_features):\n",
        "    for (attr, label), weight in state_features:\n",
        "        print(\"%0.6f %-8s %s\" % (weight, label, attr))    \n",
        "\n",
        "print(\"Top positive features:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common(30))\n",
        "\n",
        "print(\"\\nTop negative features:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Recent Advances in Sequence Labeling from Deep Learning Models\n",
        "\n",
        "Les approches pour l'étiquetage de séquence fondées sur les réseaux de neurones profonds compte trois étapes :\n",
        "1. The embedding module is the first stage that maps words into their distributed representations (pretrained word embeddings, character-\n",
        "level representations, hand-crafted features and sentence-level\n",
        "representations). \n",
        "2. The context encoder module extracts contextual features (e.g. RNN/Bi-LSTM, CNN)\n",
        "3. and the inference module predict labels and generate optimal label sequence as output of the model (e.g. SoftMax, CRF, RNN). \n",
        "\n",
        "[Zhiyong He, Zanbo Wang, Sheng Jiang. A Survey on Recent Advances in Sequence Labeling from Deep Learning Models. Published 13 November 2020. Computer Science. ArXiv](https://arxiv.org/pdf/2011.06727.pdf)\n",
        "\n"
      ],
      "metadata": {
        "id": "Qfou8ByzcflN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QUESTION \n",
        "\n",
        "* Implementing Bi-LSTM Conditional Random Field for named-entity recognition in PyTorch \n",
        "https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html"
      ],
      "metadata": {
        "id": "5Q1Lp5gzQ1dB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Quelques pointeurs pour poursuivre \n",
        "\n",
        "* https://github.com/ZubinGou/NER-BiLSTM-CRF-PyTorch\n",
        "* https://github.com/cslydia/Hire-NER\n",
        "* https://github.com/jiesutd/NCRFpp\n",
        "* https://www.kaggle.com/ab971631/ner-with-bi-lstm-crf\n",
        "* https://github.com/Jekub/Wapiti/blob/master/dat/nppattern.txt\n",
        "* https://guillaumegenthial.github.io/sequence-tagging-with-tensorflow.html\n",
        "* https://www.kaggle.com/ab971631/ner-with-bi-lstm-crf\n"
      ],
      "metadata": {
        "id": "5YOhmK_6MOxn"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "M2-ATAL-2021-22_02_Machine Learning by feature engineering - Use case : NER.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}