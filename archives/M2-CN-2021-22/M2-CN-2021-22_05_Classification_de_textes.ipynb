{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_Classification de textes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO6C9hVlHB3sn8uXhH7zlY6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolashernandez/teaching_nlp/blob/main/05_Classification_de_textes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wro6PxsF2Mh0"
      },
      "source": [
        "# Automatisation de la résolution d'une tâche de classification de textes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIYKhcsgn7JC"
      },
      "source": [
        "\n",
        "## Reconnaissance de patrons et apprentissage automatique\n",
        "\n",
        "La [**reconnaissance de patrons** (_pattern recognition_)](https://en.wikipedia.org/wiki/Pattern_recognition) désigne le processus automatique de reconnaissance de régularités dans de la donnée. Ce processus peut se spécifier davantage : \n",
        "* Classification : attribution d'une classe à chaque instance \n",
        "* Clustering : partitionnement des données \n",
        "* Régression : assigner une valeur réelle à chaque instance\n",
        "* Sequence labeling : assigner une classe à chaque membre d'une séquence d'instance \n",
        "\n",
        "L'[**apprentissage automatique (_machine learning)**](https://en.wikipedia.org/wiki/Machine_learning#Approaches) désigne des algorithmes capables d'apprendre à faire des prédictions sur la base d'expériences avec de la donnée. \n",
        "On distingue trois approches principales\n",
        "* l'apprentissage supervisé (_supervised learning_) : sur la base d'exemples d'attribution d'étiquettes à des données en entrées, la machine apprend les \"règles\" d'attribution les étiques sur de nouvelles données\n",
        "* Unsupervised learning : sans étiquetage, l'algorithme apprend à trouver la structure qui organise des données\n",
        "* Reinforcement learning : En interagissant avec un environnement dynamique,  l'algorithme apprend à accomplir un certain but (sur la base de feedback et de récompenses qu'il chercher à maximiser).\n",
        "\n",
        "L'[**ingénierie des traits (_feature engineering_)**](https://en.wikipedia.org/wiki/Feature_engineering) est le processus d'utiliser les domaines de la connaissance pour extraire des traits de la donnée brute ; sous-entendu que c'est l'homme qui définit et qui implémente les extracteurs de traits selon sa connaissance du monde à propos de la donnée. Les mots d'une représentations sac de mots peuvent constituer ces traits.\n",
        "\n",
        "\n",
        "Le [**feature learning** ou **représentation learning**](https://en.wikipedia.org/wiki/Feature_learning) désigne les techniques qui permettent à un système de découvrir automatiquement les traits/la représentation dont il a besoin pour la réalisation d'une tâche sur de la donnée brute. \n",
        "\n",
        "\n",
        "L'**approche à base de règles** désigne une procédure selon laquelle c'est l'humain qui définit les traits puis écrit les règles de prédiction.\n",
        "\n",
        "L'[**apprentissage profond (_deep learning_)**](https://en.wikipedia.org/wiki/Deep_learning#Deep_neural_networks) désigne des techniques d'apprentissage automatique qui s'appuient sur les réseaux de neurones multi-couches et qui se chargent de l'apprentissage de la représentation de la donnée aussi.\n",
        "\n",
        "L'[**apprentissage par transfert (_transfer learning_)**](https://www.tensorflow.org/tutorials/images/transfer_learning) consiste à exploiter un modèle pré-entraîné sur un grand ensemble de données à la résolution d'une certaine tâche. L'intuition est que le modèle formé sur un ensemble de données suffisamment grand et général va construire des représentations de caractéristiques (élémentaires) qui peuvent servir à d'autres tâches. \n",
        "\n",
        "Un modèle pré-entraîné **se personnalise (fine-tune)** généralement en ajoutant un classifieur au dessus du modèle pré-entraîné (par exemple une couche dense) et en entraînant ce classifieur sur la nouvelle tâche de manière supervisée. Une alternative est de \"dégeler\" les couches supérieures du modèle pré-entraîné et d'entraîner conjointement à la fois le classifieur nouvellement ajouté et les dernières couches du modèles de base. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5OdahlpGltJ"
      },
      "source": [
        "\n",
        "## Bibliothèques pour faire du _deep learning_ \n",
        "\n",
        "* [Tensorflow par Google](https://www.tensorflow.org/) développement et l'entraînement de modèles avec des solutions de créations et de déploiement d'application qui exploitent cette technologie ; détection et classification d'objets dans des images, transfert de style d'une image, classification de textes, réponse à des questions...\n",
        "* [PyTorch](https://github.com/pytorch/pytorch) par Facebook développement et l'entraînement de modèles pour la résolutation d'applications telles que la vision par ordinateur ou le traitement automatique des langues\n",
        "* [Keras](https://keras.io/) API python de haut niveau au dessus de _tensorflow_ \n",
        "* [fastai](https://docs.fast.ai/tutorial.text.html)  simplifies training fast and accurate neural nets using modern best practices (on top of _PyTorch_) ; ce sont aussi des cours en ligne\n",
        "* [ludwig](https://github.com/ludwig-ai/ludwig) Ludwig is a data-centric deep learning framework that allows users to train and test deep learning models by specifying a declarative configuration tht matches the schema of the data. It is built on top of _PyTorch_.\n",
        "* [ktrain](https://github.com/amaiya/ktrain) a lightweight wrapper for the deep learning library _TensorFlow Keras_ (and other libraries) to help build, train, and deploy neural networks and other machine learning models. Inspired by ML framework extensions like fastai and ludwig, ktrain is designed to make deep learning and AI more accessible and easier to apply for both newcomers and experienced practitioners.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxdW5mtMGqmy"
      },
      "source": [
        "##\n",
        " Classification de textes\n",
        "\n",
        "La **classification** consiste à attribuer une classe à chaque texte (objet, instance, point) à classer. On parle de *classification binaire* (_binary classification_) quand il y a deux classes. On parle de *classification en classes multiples* (_multiclass classification_) pour désigner la répartition d'un lot de textes entre plus de deux ensembles (ou classes). On parle de *classification multi-étiquettes* (_multi-label classification_) pour désigner les problèmes de classification où plusieurs étiquettes (classes) peuvent être assignées à chaque instance.\n",
        "\n",
        "Reconnaître si un email est un spam, si une photo contient une voiture... sont des problèmes de classification (binaire).\n",
        "\n",
        "Les problèmes de classification peuvent être traités par des algorithmes d'apprentissage automatique et notamment des algorithmes dits d'apprentissage profond (_deep learning_).\n",
        "\n",
        "Ci-dessous seront mis en oeuvre des approches de deep donc certaines avec personnalisation (fine tuning) aussi appelé apprentissage par transfert.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7PRm8jl2cE0"
      },
      "source": [
        "# Mise en oeuvre d'une bibliothèque de deep learning pour la résolution de problèmes de classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee8F8DyZ9v7x"
      },
      "source": [
        "\n",
        "La tâche classique d'analyse de sentiment consiste à annoter un texte donné selon une polarité positive ou négative exprimée dans le texte.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbuBLXmt3NyE"
      },
      "source": [
        "## QUESTION\n",
        "\n",
        "* Selon vous la tâche d'analyse de sentiment tel que définie juste au dessus peut se définir comme un problème de 1) classification binaire, 2) classification en classes multiples ou 3) en classification multi-étiquettes ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sjOoxLi3m7E"
      },
      "source": [
        "## VOTRE REPONSE\n",
        "\n",
        "**TODO**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h06bBaA34vf"
      },
      "source": [
        "## Installation et configuration de l'environnement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLfw1G8wMxkz"
      },
      "source": [
        "Configuration de l'environnement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ-F6wCZRYpw"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUvbU_z33-Lw"
      },
      "source": [
        "Installation de la bibliothèque ktrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxWRMgrKR7Q1"
      },
      "source": [
        "!pip install ktrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7LRCuPB4p-y"
      },
      "source": [
        "Import de la bibliothèque ktrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2avp8suURzMT"
      },
      "source": [
        "# Execution time 30 s\n",
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE0PnqNnM1tB"
      },
      "source": [
        "Récupération de la donnée"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRNckNWIM4N6"
      },
      "source": [
        "# Récupération\n",
        "!wget -nc https://github.com/nicolashernandez/teaching_nlp/raw/main/data/allocine-train-10000.zip -P data\n",
        "!unzip data/allocine-train-10000.zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYGyWUwn9yPS"
      },
      "source": [
        "## Fonctionnement de ktrain\n",
        "\n",
        "\n",
        "Pour réaliser cette tâche de classification nous allons utiliser la bibliothèque ktrain pour faire un apprentissage par transfert.\n",
        "\n",
        "Les étapes sont les suivantes\n",
        "1. chargement des données avec application d'un prétraitement défini à la volée\n",
        "2. construction d'un modèle de classification sur la base d'un modèle pré-entraîné spécifié\n",
        "3. récupération d'une instance du modèle pour la personnalisation de celui-ci\n",
        "4. recherche d'un bon taux d'apprentissage\n",
        "5. entraînement du classifieur i.e. personnalisation du modèle de base à l'aide d'un taux d'apprentissage défini\n",
        "6. utilisation du nouveau modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAvPw6g49WGa"
      },
      "source": [
        "*ETAPE 1 :* \n",
        "\n",
        "Le type de pré-traitement est fonction du modèle pré-entraîné spécifié."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTBW_SEO9mXi"
      },
      "source": [
        "*ETAPE 2 :*\n",
        "\n",
        "ktrain vient avec quelques modèles pré-entraînés packagés. Pour les connaître, exécutez : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7FvrdBC9n2W"
      },
      "source": [
        "text.print_text_classifiers()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae1TJ5nk_K7G"
      },
      "source": [
        "Vous connaissez **fasttext**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XtFCEfYWchi"
      },
      "source": [
        "[**NBSVM**](https://medium.com/@asmaiya/a-neural-implementation-of-nbsvm-in-keras-d4ef8c96cb7c) is an approach to text classification proposed by [Wang and Manning](https://www.aclweb.org/anthology/P12-2018) that takes a linear model such as SVM (or logistic regression) and infuses it with Bayesian probabilities by replacing word count features with Naive Bayes log-count ratios. Despite its simplicity, NBSVM models have been shown to be both fast and powerful across a wide range of different text classification datasets. \n",
        "Keras offers a NBSVM model implemented as a neural network using two embedding layers. The first stores the Naive Bayes log-count ratios. The second stores learned weights (or coefficients) for each feature (i.e., word) in this linear model. The prediction, then, is simply the dot product of these two vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0H3RJMw_xhB"
      },
      "source": [
        "**BERT** (_Bidirectional Encoder Representations from Transformers_), proposé par [Google AI Language](https://arxiv.org/pdf/1810.04805.pdf) est un encodeur bidirectionnel qui applique un modèle d'attention Transformers à la modélisation du language (_language modeling_). Il représente l'état de l'art.\n",
        "Les Transformers sont un mécanisme d'attention qui apprennent les relations contextuelles entre les mots dans un texte.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB3bN2mE_xyi"
      },
      "source": [
        "Il est possible d'[**encapsuler les modèles Transformers du site _hugging face_**](https://github.com/amaiya/ktrain/blob/master/tutorials/tutorial-A3-hugging_face_transformers.ipynb). _hugging face_ diffuse les [modèles Transformers pré-entraînés \"officiels\"](https://huggingface.co/transformers/pretrained_models.html) ainsi que les [modèles Transformers construits par la communauté](https://huggingface.co/models).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wINsCEpD1-s"
      },
      "source": [
        "*ETAPE 4 :*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4syPI6CI6Vt6"
      },
      "source": [
        "Le **taux d'apprentissage (_learning rate_)** est un hyperparamètre qui contrôle combien le modèle doit changer en réponse à l'erreur estimée à chaque fois que les poids du modèles sont mis à jour. Choisir un 'lr' trop petit conduit à une longue phase d'entraînement qui peut resté bloquée. Choisir un 'lr' trop grand conduit à un apprentissage sous-optimal des poids et à une instabilité du processus d'entraînement. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWKzuQDbBBuT"
      },
      "source": [
        "#### QUESTION\n",
        "* Un modèle français est-il disponible pour une tâche de conversation/chatbot sur le dépôt communautaire de hugging face ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ5-yaBwBWe4"
      },
      "source": [
        "#### VOTRE REPONSE\n",
        "\n",
        "**TODO**\n",
        "\n",
        "oui, mais ne pas l'essayer car trop mauvais https://huggingface.co/cedpsam/chatbot_fr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMJHB4zgRCTw"
      },
      "source": [
        "## FastText\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPc3RUc_TYDc"
      },
      "source": [
        "*ETAPE 1 :* \n",
        "\n",
        "La méthode [`texts_from_csv`](https://amaiya.github.io/ktrain/text/index.html#ktrain.text.texts_from_csv) charge le corpus, normalise les documents (définit un préprocesseur réutilisable), et découpe la collection en données d'entraînement et données de validation.\n",
        "\n",
        "```\n",
        "* train_filepath(str): file path to training CSV\n",
        "* text_column(str): name of column containing the text\n",
        "* label_column(list): list of columns that are to be treated as labels\n",
        "* val_filepath(string): file path to test CSV.  If not supplied, 10% of documents in training CSV will be used for testing/validation.\n",
        "* max_features(int): max num of words to consider in vocabulary ; Note: This is only used for preprocess_mode='standard'.\n",
        "* maxlen(int): each document can be of most <maxlen> words. 0 is used as padding ID.\n",
        "* ngram_range(int): size of multi-word phrases to consider e.g., 2 will consider both 1-word phrases and 2-word phrases limited by max_features\n",
        "* preprocess_mode (str):  Either 'standard' (normal tokenization) or one of {'bert', 'distilbert'} tokenization and preprocessing for use with                BERT/DistilBert text classification model.\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwk-qlw_ZbLW"
      },
      "source": [
        "DATA_PATH = 'data/allocine-train-10000.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9whXoR9R2j6"
      },
      "source": [
        "# fasttext\n",
        "#NUM_WORDS = 50000\n",
        "#MAXLEN = 150\n",
        "#NGRAMS_SIZE = 1# 1 # 8 minutes avec 2\n",
        "# nbsvm \n",
        "#NUM_WORDS = 80000\n",
        "#MAXLEN = 2000\n",
        "#NGRAMS_SIZE = 3\n",
        "\n",
        "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_csv(DATA_PATH,\n",
        "                      'review',\n",
        "                      label_columns = [\"negative\", \"positive\"],\n",
        "                      val_filepath=None, # if None, 10% of data will be used for validation\n",
        "                      #max_features=NUM_WORDS, \n",
        "                      #maxlen=MAXLEN,\n",
        "                      ngram_range=NGRAMS_SIZE,\n",
        "                      preprocess_mode='standard' # default\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LktiVGh8NVSW"
      },
      "source": [
        "Observons les 5 premières des données prétraitées. `x_` représente la donnée et `y_` la classe. On note que les données ont été transformées. Chaque mot est remplacé par un identifiant. On note que la classe est décrite par 2 colonnes avec deux codes \"1 0\" et \"0 1\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzzWhW3ZHAq8",
        "outputId": "6c2087a5-1515-456f-856a-472b778d8939"
      },
      "source": [
        "print ('x_train', x_train[:5])\n",
        "print ('y_train', y_train[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train [[   0    0    0 ...   23   14   49]\n",
            " [   0    0    0 ...   17  122 6939]\n",
            " [   0    0    0 ...    6 1041 2810]\n",
            " [   0    0    0 ...   19   92 3577]\n",
            " [   0    0    0 ...   73  786   72]]\n",
            "y_train [[1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHhCXpcQOPje"
      },
      "source": [
        "*ETAPE 2 et 3:* \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3jEacvRRuih"
      },
      "source": [
        "# Build and return a text classification model https://amaiya.github.io/ktrain/text/index.html#ktrain.text.text_classifier\n",
        "model = text.text_classifier('fasttext', (x_train, y_train), preproc=preproc)\n",
        "\n",
        "# Returns a Learner instance that can be used to tune and train Keras models https://amaiya.github.io/ktrain/index.html#ktrain.get_learner\n",
        "learner = ktrain.get_learner(model, train_data=(x_train, y_train), val_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufKylXAeOVCU"
      },
      "source": [
        "*ETAPE 4 :* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9_32BN5Ur7e"
      },
      "source": [
        "# recherche d'un bon taux d'apprentissage \n",
        "learner.lr_find()\n",
        "learner.lr_plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0eWERAHZ_Go"
      },
      "source": [
        "*ETAPE 5 :* \n",
        "\n",
        "[autofit](https://amaiya.github.io/ktrain/core.html#ktrain.core.Learner.autofit)\n",
        "Automatically train model using a default learning rate schedule shown to work well in practice.  By default, this method currently employs a triangular learning rate policy (https://arxiv.org/abs/1506.01186).  \n",
        "During each epoch, this learning rate policy varies the learning rate from lr/10 to lr and then back to a low learning rate that is near-zero. \n",
        "If epochs is None, then early_stopping and reduce_on_plateau are atomatically\n",
        "set to 6 and 3, respectively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOMvkq1ZPXV2"
      },
      "source": [
        "#### QUESTION\n",
        "\n",
        "* Sur le graph ci-dessus, repérez approximativement la puissance n de 1/10^n où la chute de la loss devient importante. Testez avec cette valeur comme learning rate, observez votre performance (accuracy) sur le train et le val.\n",
        "\n",
        "Dans l'extrait de log ci-dessous, loss et accuracy concerne le corpus de train tandis que  val_loss et val_accuracy le corpus de validation.\n",
        "```\n",
        "282/282 [==============================] - 7s 25ms/step - loss: 0.1105 - accuracy: 0.9566 - val_loss: 0.3318 - val_accuracy: 0.8911\n",
        "```\n",
        "* Est-ce normal d'observer un écart d'accuracy entre le train et le val ?\n",
        "* Stoquez le score obtenu en dernière étape, et relancez le finetuning sans changer le paramétrage. Obtenez-vous les mêmes résultats ? Pourquoi ? La réponse est à chercher dans l'initiatilisation des poids du réseau neuronal.\n",
        "* Volontairement tester des lr avec d'autres puissances de 10 (0.1, 0.01, 0.001, 0.0001). Est-ce que cela marche mieux ? \n",
        "\n",
        "Mon meilleur score est `loss: 0.1615 - accuracy: 0.9384 - val_loss: 0.2864 - val_accuracy: 0.8931` et vous ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vY7oJU7U4G0"
      },
      "source": [
        "learner.autofit(0.00001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqItionrS_z0"
      },
      "source": [
        "#### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySqltk4KTHJ7"
      },
      "source": [
        "*ETAPE 6 :* Le code ci-dessous permet d'utiliser le modèle. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOiht1hPani6"
      },
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc)\n",
        "\n",
        "data = [ \"Ce film était horrible ! L'intrigue était ennuyeuse. Le jeu d'acteur était correct, cependant.\",\n",
        "         \"Le film est vraiment nul. Je veux qu'on me rende mon argent.\",\n",
        "        \"Quelle belle comédie romantique. 10/10 à revoir !\"]\n",
        "\n",
        "predictor.predict(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5l8TyRWThZF"
      },
      "source": [
        "#### QUESTION\n",
        "\n",
        "* Tester le modèle. Arrivez-vous à piéger le modèle ? Avec quelle phrase (donnez le code)*texte en italique*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkowscJhTiPh"
      },
      "source": [
        "#### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApxsjcDHE4Im"
      },
      "source": [
        "## NBSVM\n",
        "\n",
        "Le code ci-dessous utilise le même pré-traitement que précédemment et applique un modèle neuronal plus \"simple\" que fasttext.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGp2mrBsg17I"
      },
      "source": [
        "# load an NBSVM model\n",
        "model = text.text_classifier('nbsvm', (x_train, y_train), preproc=preproc)\n",
        "learner = ktrain.get_learner(model, train_data=(x_train, y_train), val_data=(x_test, y_test))\n",
        "\n",
        "# fine tune\n",
        "LEARNING_RATE = 0.01\n",
        "learner.autofit(LEARNING_RATE)\n",
        "\n",
        "# Finally, we will fit our model using and [SGDR learning rate](https://github.com/amaiya/ktrain/blob/master/example-02-tuning-learning-rates.ipynb) schedule by invoking the fit method with the cycle_len parameter (along with the cycle_mult parameter).\n",
        "# learner.fit(0.001, 3, cycle_len=1, cycle_mult=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xveDFwSnUzj1"
      },
      "source": [
        "#### QUESTION\n",
        "\n",
        "* Le modèle nbsvm est-il plus performant que le précédent ? Vous pouvez tester aussi différents learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilof7YlQNtfz"
      },
      "source": [
        "## BERT \n",
        "\n",
        "L'usage du modèle bert requiert que l'on change le prétraitement des données en entrée. Le code suivant réalise le prétraitement, charge un modèle bert et lance la personnalisation (fine tuning) sur 1 cycle avec taux d'apprentissage fixé.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kpI2LG_Wvqe"
      },
      "source": [
        "#### QUESTION\n",
        "* Exécutez le code en observant l'occupation de la RAM et attendez jusqu'à voir le temps prévisionnel s'afficher. Etes-vous choqué par le temps affiché ? Bert est très gros. Il requiert un peu de temps...\n",
        "* Stoppez l'exécution dans la cellule, et tentez de changer la taille du batch_size (quantité de données traitées en même temps). Vous pouvez tester 128 et 12 comme valeurs. Ne lachez pas la barre de la RAM des yeux. Ça passe ? Quel problème rencontrez-vous ? \n",
        "* Passez à la suite..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ujB3xihhnG"
      },
      "source": [
        "# ETAPE 1\n",
        "DATA_PATH = 'data/allocine-train-10000.csv'\n",
        "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_csv(DATA_PATH, \n",
        "                      'review',\n",
        "                      label_columns = [\"negative\", \"positive\"],\n",
        "                      val_filepath=None, # if None, 10% of data will be used for validation\n",
        "                      ##max_features=NUM_WORDS, \n",
        "                      #maxlen=MAXLEN,\n",
        "                      #ngram_range=NGRAMS_SIZE,\n",
        "                      preprocess_mode='bert' \n",
        "                      )\n",
        "# ETAPE 2 et 3\n",
        "model = text.text_classifier('bert', (x_train, y_train) , preproc=preproc)\n",
        "learner = ktrain.get_learner(model, \n",
        "                             train_data=(x_train, y_train), \n",
        "                             val_data=(x_test, y_test), \n",
        "                             batch_size=6)\n",
        "# ETAPE 5\n",
        "learner.fit_onecycle(2e-5, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WveM1n9KFNx6"
      },
      "source": [
        "## Mode d'exécution GPU de Google Colab\n",
        "\n",
        "Utilisiez-vous une GPU jusqu'à présent ou bien utilisiez-vous un CPU ? Que vous dis le code ci-dessous ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwHyWGuWiCUu"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "# https://medium.com/@oribarel/getting-the-most-out-of-your-google-colab-2b0585f82403\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "#\n",
        "\n",
        "if len(GPUs) >0: \n",
        "  gpu = GPUs[0]\n",
        "  printm()\n",
        "else:\n",
        "  print ('no GPU. Are you sure the hardware accelerator is configured to GPU? To do this go to Runtime→Change runtime type and change the Hardware accelerator to GPU.') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxVCJnn3OBq2"
      },
      "source": [
        "\n",
        "> To use the google colab in a GPU mode you have to make sure the hardware accelerator is configured to GPU. To do this go to Runtime→Change runtime type and change the Hardware accelerator to GPU. Sometimes, all GPUs are in use and there is no GPU available.\n",
        "\n",
        "Une fois configuré le GPU, vérifiez l'état de la mémoire sur la carte en réexécutant le code \"memory footprint\" ci-dessus. Le message a-t-il changé favorablement ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Cuf-4taGTU"
      },
      "source": [
        "#### QUESTION\n",
        "*  Réexécuter aussi toute l'installation et la configuration de l'environnement. Puis réexécuter la personnalisation de BERT. Le temps d'entraînement a-t-il diminué ? D'un facteur de combien diriez-vous  ? Interrompez l'exécution et passer à la suite\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T5wCkAoaQh7"
      },
      "source": [
        "#### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0r6CivJbBUF"
      },
      "source": [
        "## Modèle \"à la bert\" issu de hugging face\n",
        "\n",
        "On va tester un modèle encore plus léger 'distilbert-base-uncased'. Exécutez toutes les cellules de code ci-dessous. Laissez tourner et répondez aux questions.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_VN1VpGJIMH"
      },
      "source": [
        "from csv import DictReader\n",
        "\n",
        "DATA_PATH = 'data/allocine-train-10000.csv'\n",
        "\n",
        "X = list()\n",
        "Y = list()\n",
        "\n",
        "# open file in read mode\n",
        "with open(DATA_PATH, 'r') as read_obj:\n",
        "    # pass the file object to reader() to get the reader object\n",
        "    csv_dict_reader = DictReader(read_obj)\n",
        "    # get column names from a csv file\n",
        "    column_names = csv_dict_reader.fieldnames\n",
        "    print(column_names)\n",
        "    for row in csv_dict_reader:\n",
        "        #print(row['review'], row['positive'], row['negative'])\n",
        "        X.append(row['review'])\n",
        "        Y.append(row['positive'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mgSuqwmG0J2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
        "print ('x_train', len(x_train), x_train[:10])\n",
        "print ('y_train',  len(y_train), y_train[:10])\n",
        "print ('x_train', len(x_test), x_test[:10])\n",
        "print ('y_train',  len(y_test), y_test[:10])\n",
        "\n",
        "# convert a list of string into lists of int then into np.array\n",
        "import numpy as np\n",
        "y_train = np.array(list(map(int, y_train)))\n",
        "y_test = np.array(list(map(int, y_test)))\n",
        "\n",
        "print ('x_train', len(x_train), x_train[:10])\n",
        "print ('y_train',  len(y_train), y_train[:10])\n",
        "print ('x_train', len(x_test), x_test[:10])\n",
        "print ('y_train',  len(y_test), y_test[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52DqPKJE9d4s"
      },
      "source": [
        "import ktrain\n",
        "from ktrain import text\n",
        "MODEL_NAME = 'distilbert-base-uncased'\n",
        "#MODEL_NAME = 'albert-base-v2'\n",
        "CLASS_NAMES = [\"negative\", \"positive\"]\n",
        "\n",
        "t = text.Transformer(MODEL_NAME, maxlen=500, class_names=CLASS_NAMES)\n",
        "trn = t.preprocess_train(x_train, y_train)\n",
        "val = t.preprocess_test(x_test, y_test)\n",
        "#print (type(trn))\n",
        "#x_train, y_train = trn\n",
        "#x_test, y_test = val  \n",
        "model = t.get_classifier()\n",
        "# batch_size (int):              Batch size to use in training. default:32  \n",
        "#learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=6) # 128 dépend de la ram dispo 13 Go par défaut\n",
        "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=12)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqM1-j84-4eD"
      },
      "source": [
        "learner.fit_onecycle(0.01, 1)\n",
        "#learner.fit_onecycle(8e-5, 4)\n",
        "#8e-5 = 8 + 10^(-5)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeM-jNIyb_7M"
      },
      "source": [
        "#### QUESTION\n",
        "* Quelle performance j'obtiens comparativement aux 2 modèles précédents nbsvm et fasttext ?\n",
        "* Quelles risques je prends à ne pas réaliser les mêmes prétraitements ou  normalisations (voire utiliser des outils différents pour réaliser les mêmes prétraitements ou normalisations supposées) que ceux réalisés sur les corpus ayant servis à construire les modèles ? \n",
        "* En résumé, en mettant dans la balance les questions de performance, les questions de taille de modèles, de temps de personnalisation... quelles conclusions faites-vous de l'usage des modèles simples vs les modèles plus complexes à la BERT ?\n",
        "\n",
        "Si le code tourne toujours passez à la question suivante pour gagner du temps..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qni8ELuBcBB1"
      },
      "source": [
        "#### VOTRE REPONSE\n",
        "\n",
        "**TODO**\n",
        "\n",
        "La performance de BERT est très similaire. Le temps obtenu est beaucoup long."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DJ8-vccGwrP"
      },
      "source": [
        "# Génération de textes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LogIfuPQIQ1f"
      },
      "source": [
        "#### QUESTION\n",
        "\n",
        "* Parmi les ressources communautaires de hugging face, recherchez la ressource de génération de texte qui utilise le modèle `gpt-fr-cased-base` pour le français. Donnez le lien de la page et mettez en oeuvre le code mis à disposition en réduisant le paramètre `max_length` et `top_k` respectivement à `20` et `10`. Vous pouvez chercher à quoi servent ces paramètres...\n",
        "\n",
        "Pour aller plus loin au sujet de [GPT2](https://huggingface.co/transformers/model_doc/gpt2.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvCpKgxJITi0"
      },
      "source": [
        "#### VOTRE REPONSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyEqlMYvGy-2"
      },
      "source": [
        "#TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYZWqH9RIvL0"
      },
      "source": [
        "Le code suivant encapsule la partie génération... _accidentellement_ le paramètre `top_k` est passé à 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q_T0duJIuek"
      },
      "source": [
        "def generate (input_sentence):\n",
        "  input_ids = tokenizer.encode(input_sentence, return_tensors='pt')\n",
        "  beam_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length=20, \n",
        "    do_sample=True,   \n",
        "    top_k=1, \n",
        "    top_p=0.95, \n",
        "    num_return_sequences=1\n",
        "  )\n",
        "  print(\"Output:\\n\" + 100 * '-')\n",
        "  print(tokenizer.decode(beam_outputs[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpqf6EMMKdkE"
      },
      "source": [
        "... afin de pouvoir l'utiliser à votre guise : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2pK6ZFuKaPB"
      },
      "source": [
        "input_sentence = \"Mon mari vient d'obtenir un nouveau poste en tant\"\n",
        "generate (input_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezV_qzBWKmZ5"
      },
      "source": [
        "#### QUESTION\n",
        "\n",
        "* Quels sont les professions que le modèle génère pour \"Mon mari vient d'obtenir un nouveau poste en tant\" ? \"Ma femme vient d'obtenir un nouveau poste en tant\" ? Si vous augmentez la valeur du paramètre `top_k` e.g. 5, 10 ou 20, observe-vous la même chose ?\n",
        "* Essayez de trouver des phrases générées par le modèle qui témoignent de biais de sexe, de genre ou autre. Fournissez votre code. Que concluez-vous ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eneLhpRZLLu8"
      },
      "source": [
        "#### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9pS013LXHL"
      },
      "source": [
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tzxoRA_RGl4"
      },
      "source": [
        "# Références\n",
        "* Text Classification Example: Sentiment Analysis with IMDb Movie Reviews¶ https://nbviewer.org/github/amaiya/ktrain/blob/master/tutorials/tutorial-04-text-classification.ipynb\n",
        "* https://nbviewer.org/github/amaiya/ktrain/blob/master/examples/text/IMDb-BERT.ipynb\n",
        "* ktrain examples of Binary text Classification (Sentiment Analysis with IMDb Movie Reviews) with a nbsvm model (also a bit of bert)  and \n",
        "Multi-Label Text Classification (toxic comments) with fasttext https://nbviewer.org/github/amaiya/ktrain/blob/master/tutorials/tutorial-04-text-classification.ipynb\n",
        "* Text Classification with Hugging Face Transformers in ktrain https://github.com/amaiya/ktrain/blob/master/tutorials/tutorial-A3-hugging_face_transformers.ipynb\n",
        "* ktrain api documentation https://amaiya.github.io/ktrain/\n"
      ]
    }
  ]
}
