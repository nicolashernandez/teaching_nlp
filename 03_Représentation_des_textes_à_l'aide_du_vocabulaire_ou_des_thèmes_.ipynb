{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPxasV47tsQRUoYXXGPVedN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolashernandez/teaching_nlp/blob/main/03_Repr%C3%A9sentation_des_textes_%C3%A0_l'aide_du_vocabulaire_ou_des_th%C3%A8mes_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modélisation du contenu des textes - approches traditionnelles\n",
        "\n",
        "Représentation du sens au niveau des mots, et des documents - approche naive à la Salton et Spark Jones\n",
        "\n"
      ],
      "metadata": {
        "id": "siusz3BBGiY0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmNr9PDicuOn"
      },
      "source": [
        "## Modèle \"sac de mots\"\n",
        "\n",
        "Le [**sac de mots** ou *BOW* pour *Bag Of Words* en anglais](https://fr.wikipedia.org/wiki/Sac_de_mots) est un modèle classique utilisé en Recherche d'Information (RI) pour représenter le contenu d'un document. Chaque document est décrit vis-à-vis d'un vocabulaire donné commun. \n",
        "\n",
        "Différentes vues sont possibles : \n",
        "- compter binairement si les mots du vocabulaire sont présents dans le document, \n",
        "- compter les occurrences des mots du vocabulaire dans le document, \n",
        "- pondérer les mots en tenant compte de leurs spécificités dans le document vis-à-vis des autres documents (on parle de pondération _tf-idf_).\n",
        "\n",
        "La **vectorisation** est le processus qui désigne transformation des textes en vecteurs (de mots selon une modélisation *bow*).\n",
        "\n",
        "On doit à [Karen Spärck Jones](https://fr.wikipedia.org/wiki/Karen_Sp%C3%A4rck_Jones) la proposition de la pondération _tf-idf_ des termes.\n",
        "> « La spécificité d'un terme peut être quantifiée comme une fonction inverse du nombre de documents dans lesquels il apparaît. » \n",
        "\n",
        "[Gérard Salton](https://fr.wikipedia.org/wiki/Gerard_Salton), quant à lui, est reconnu comme étant le père de la recherche d'information en ayant proposé une modélisation des documents dans un espace vectoriel. \n",
        "\n",
        "\n",
        "* Karen Spärck Jones, « A statistical interpretation of term specificity and its application in retrieval », Journal of Documentation, vol. 28, no 1,‎ 1972, p. 11–21 (DOI 10.1108/eb026526)\n",
        "* G. Salton , A. Wong , C. S. Yang, A vector space model for automatic indexing, Communications of the ACM, v.18 n.11, p. 613-620, novembre 1975\n",
        "\n",
        "Par la suite nous utiliserons le module python sklearn qui offre des facilités pour pré-traiter (normaliser) et vectoriser aisément les textes, puis de réaliser des opérations de calcul de similarités inter-documents ou de clustering au sein d'un ensemble de documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPtnCbGo1-IZ"
      },
      "source": [
        "## Préparation d'un jeu de données \"jouet\"\n",
        "\n",
        "Le code suivant définit un corpus de **huit documents**, chacun pré-classé dans une catégorie thématique. Lisez les phrases et constatez qu'il y a **trois catégories** thématiques qui émergent de ce corpus. Les documents sont ici simplifiées à une seule phrase. On peut aussi constater que les documents ne sont pas normalisés."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GECHxKx82PiX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "3432204f-aec2-498d-c679-9610068e817e"
      },
      "source": [
        "import pandas as pd\n",
        "pd.options.display.max_colwidth = 200\n",
        "import numpy as np\n",
        "\n",
        "corpus = ['The sky is blue and beautiful.',\n",
        "          'Love this blue and beautiful sky!',\n",
        "          'The quick brown fox jumps over the lazy dog.',\n",
        "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
        "          'I love green eggs, ham, sausages and bacon!',\n",
        "          'The brown fox is quick and the blue dog is lazy!',\n",
        "          'The sky is very blue and the sky is very beautiful today',\n",
        "          'The dog is lazy but the brown fox is quick!'    \n",
        "]\n",
        "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']\n",
        "\n",
        "corpus = np.array(corpus)\n",
        "corpus_df = pd.DataFrame({'Document': corpus, 'Category': labels})\n",
        "corpus_df = corpus_df[['Document', 'Category']]\n",
        "corpus_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                             Document Category\n",
              "0                                      The sky is blue and beautiful.  weather\n",
              "1                                   Love this blue and beautiful sky!  weather\n",
              "2                        The quick brown fox jumps over the lazy dog.  animals\n",
              "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans     food\n",
              "4                         I love green eggs, ham, sausages and bacon!     food\n",
              "5                    The brown fox is quick and the blue dog is lazy!  animals\n",
              "6            The sky is very blue and the sky is very beautiful today  weather\n",
              "7                         The dog is lazy but the brown fox is quick!  animals"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5dd546c6-623d-461b-9280-3901c47895dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The sky is blue and beautiful.</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this blue and beautiful sky!</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The dog is lazy but the brown fox is quick!</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dd546c6-623d-461b-9280-3901c47895dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5dd546c6-623d-461b-9280-3901c47895dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5dd546c6-623d-461b-9280-3901c47895dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBUAsxjCKEe9"
      },
      "source": [
        "## Vectorisation avec occurrences\n",
        "\n",
        "Le code suivant réalise une vectorisation du corpus en comptant les occurrences des mots. La vectorisation prend en charge la construction d'un vocabulaire sur le corpus ainsi que quelques pré-traitements de normalisation linguistiques. Enfin le résultat de la vectorisation est affiché sous la forme d'une matrice **document-terme** (les documents sont en ligne et les mots en colonne). \n",
        "Nous aurons une matrice de dimension _nb de documents * taille du vocabulaire_.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5faoVA63PSE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "ebf6e212-ffef-4bbb-a05e-4dccc36946a8"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# define the vectorizer\n",
        "c_vectorizer = CountVectorizer(stop_words='english')\n",
        "\n",
        "# display the configuration of the vectorizer\n",
        "print (c_vectorizer)\n",
        "\n",
        "# perform the vectorization\n",
        "c_matrix = c_vectorizer.fit_transform(corpus)\n",
        "print ('Matrix dimensions:', c_matrix.get_shape())\n",
        "\n",
        "# get all unique words in the corpus (the vocabulary and also the names of the matrix columns/features)\n",
        "vocab = c_vectorizer.get_feature_names()\n",
        "print ('Vocabulary size:', len(vocab))\n",
        "\n",
        "# show document-term matrix\n",
        "c_matrix = c_matrix.toarray()\n",
        "pd.DataFrame(c_matrix, columns=vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer(stop_words='english')\n",
            "Matrix dimensions: (8, 20)\n",
            "Vocabulary size: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   bacon  beans  beautiful  blue  breakfast  brown  dog  eggs  fox  green  \\\n",
              "0      0      0          1     1          0      0    0     0    0      0   \n",
              "1      0      0          1     1          0      0    0     0    0      0   \n",
              "2      0      0          0     0          0      1    1     0    1      0   \n",
              "3      1      1          0     0          1      0    0     1    0      0   \n",
              "4      1      0          0     0          0      0    0     1    0      1   \n",
              "5      0      0          0     1          0      1    1     0    1      0   \n",
              "6      0      0          1     1          0      0    0     0    0      0   \n",
              "7      0      0          0     0          0      1    1     0    1      0   \n",
              "\n",
              "   ham  jumps  king  lazy  love  quick  sausages  sky  toast  today  \n",
              "0    0      0     0     0     0      0         0    1      0      0  \n",
              "1    0      0     0     0     1      0         0    1      0      0  \n",
              "2    0      1     0     1     0      1         0    0      0      0  \n",
              "3    1      0     1     0     0      0         1    0      1      0  \n",
              "4    1      0     0     0     1      0         1    0      0      0  \n",
              "5    0      0     0     1     0      1         0    0      0      0  \n",
              "6    0      0     0     0     0      0         0    2      0      1  \n",
              "7    0      0     0     1     0      1         0    0      0      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f49e9db-e007-4a07-87d4-9560d845c574\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bacon</th>\n",
              "      <th>beans</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>breakfast</th>\n",
              "      <th>brown</th>\n",
              "      <th>dog</th>\n",
              "      <th>eggs</th>\n",
              "      <th>fox</th>\n",
              "      <th>green</th>\n",
              "      <th>ham</th>\n",
              "      <th>jumps</th>\n",
              "      <th>king</th>\n",
              "      <th>lazy</th>\n",
              "      <th>love</th>\n",
              "      <th>quick</th>\n",
              "      <th>sausages</th>\n",
              "      <th>sky</th>\n",
              "      <th>toast</th>\n",
              "      <th>today</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f49e9db-e007-4a07-87d4-9560d845c574')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f49e9db-e007-4a07-87d4-9560d845c574 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f49e9db-e007-4a07-87d4-9560d845c574');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7aCCq_A6wr-"
      },
      "source": [
        "### QUESTION : configuration du vectorizer\n",
        "\n",
        "Pour vous aider dans les questions suivantes, consulter l'affichage du paramétrage du `CountVectorizer` (via la ligne `print (vectorizer)`). Consulter aussi la documentation https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "\n",
        "Si besoin, vous pouvez aussi consulter une aide sur les expressions régulières en dessous des questions.\n",
        "\n",
        "Répondez aux questions suivantes :\n",
        "* Quels prétraitements de normalisation sont opérées (mentionner les paramètres impliqués) ? \n",
        "* D'autres pré-traitement de normalisation sont-ils possibles même s'ils ne sont pas utilisées ici (mentionner les paramètres impliqués) ? \n",
        "* Comment expliquez-vous que les mots du vocabulaire ne comptent de marques de ponctuation accolées ? \n",
        "* Le paramètre `max_df` permet de fixer une fréquence documentaire maximale pour les mots à considérer dans le vocabulaire. Expliquez pourquoi les valeurs `1` et `1.0` n'ont pas la même signification.\n",
        "* Comment paramétrer le `CountVectorizer` pour qu'il binarise les valeurs au lieu de compter les nombres d'occurrences ?\n",
        "\n",
        "Explicitation de quelques séquences spéciales de caractères dans les expressions régulières :   \n",
        "* `(?u)` switches on the re.U (re.UNICODE) flag for this expression https://docs.python.org/2/library/re.html#re.U. Note that for backward compatibility, the re.U flag still exists (as well as its synonym re.UNICODE and its embedded counterpart (?u)), but these are redundant in Python 3 since matches are Unicode by default for strings (and Unicode matching isn’t allowed for bytes).\n",
        "* `\\w` represents a word character. For Unicode (str) patterns: \n",
        "matches characters considered alphanumeric in the ASCII character set; this is equivalent to `[a-zA-Z0-9_]`. For 8-bit (bytes) patterns: Matches Unicode word characters; this includes most characters that can be part of a word in any language, as well as numbers and the underscore. https://docs.python.org/3/library/re.html\n",
        "* `\\b` represents a word boundary between a word character and a non-word character. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDEKVUL75aw1"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "**TODO**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL5ftk5iK9Ag"
      },
      "source": [
        "### QUESTION : matrice creuse ou matrice dense\n",
        "\n",
        "\n",
        "Une [**matrice creuse**, ou _sparse matrix_ en anglais](https://fr.wikipedia.org/wiki/Matrice_creuse), est une matrice qui contient beaucoup de valeurs nulles. A l'inverse on parle de **matrice pleine** (ou _dense matrix_). \n",
        "\n",
        "* Selon vous, la matrice obtenue après vectorisation est-elle creuse ou pleine ? Pour vous aider dans votre réponse, diriez-vous que la majorité des mots du vocabulaire se produit dans chaque document ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H_mmjqxN2gr"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "**TODO**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIuWsNULPULG"
      },
      "source": [
        "## Vectorisation avec TF-IDF\n",
        "\n",
        "La vectorisation avec occurrences présente des limites lorsqu'elle est utilisée sur de large corpus. En effet, le modèle présume que l'importance des mots est fonction de sa fréquence et qu'un mot plus fréquent qu'un autre dans un document est plus discriminant que l'autre. Le problème intervient quand un mot fréquent, supposé important, apparaît dans plusieurs documents. Le fait qu'il apparaisse dans plusieurs documents peut au final le rendre moins discriminant que d'autres pourtant moins fréquents. Le problème vient du fait que l'on prenne des valeurs absolues. \n",
        "\n",
        "Le modèle **TF-IDF** vise à solutionner ce problème en normalisant le compte des occurrences. TF-IDF correspond à _Term Frequency-Inverse Document Frequency_. \n",
        "\n",
        "On définit le TF-IDF comme suit: `tfidf = tf x idf`\n",
        "* `tfidf(w, D)` est le score TF-IDF du mot `w` dans le document `D`\n",
        "* `tf(w, D)` représente le nombre d'occurrence du terme `w` dans le document `D` \n",
        "* `idf(w, D)` représente la fréquence inverse documentaire du terme `w`, qui peut être calculée comme le log du nombre total de documents dans le corpus `C` divisé par la fréquence documentaire du terme `w` (i.e. le nombre de documents du corpus `C` dans lequel le terme `w` se produit).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLKloRqeX_RN"
      },
      "source": [
        "### QUESTION\n",
        "\n",
        "La vectorisation TF-IDF est prise en charge par la classe `sklearn.feature_extraction.text.TfidfVectorizer` décrite dans la documentation :\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "\n",
        "* Complétez la cellule de code ci-dessous pour opérer une vectorisation de type TF-IDF, et afficher le résultat. La ligne de code suivante permet d'arrondir des valeurs réelles à deux chiffres après la virgule `matrix = np.round(matrix, 2)`, ce qui facilite la visualisation.\n",
        "* Après avoir consulté la documentation, est-il possible d'implémenter des variantes au calcul du TD-IDF ? \n",
        "* Par défaut les modèles sac de mots ne capturent pas l'ordre des mots. Que cela soit pour la classe `CountVectorizer` ou `TfidfVectorizer`, quel paramètre offre un moyen de considérer l'ordre des mots dans une modélisation ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tXwnnSMYiZn"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "**TODO**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ5IFFd_WG2q"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TODO\n",
        "\n",
        "# define the vectorizer\n",
        "# tfidf_vectorizer = #TODO\n",
        "\n",
        "# display the configuration of the vectorizer\n",
        "# print (tfidf_vectorizer)\n",
        "\n",
        "# perform the vectorization\n",
        "# tfidf_matrix = ... #TODO\n",
        "# print ('Matrix dimensions:', tfidf_matrix.get_shape())\n",
        "\n",
        "# get all unique words in the corpus (the vocabulary and also the names of the matrix columns/features)\n",
        "# TODO\n",
        "\n",
        "# show document-term matrix\n",
        "# TODO\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Sl28YhUf3I"
      },
      "source": [
        "## Partitionnement sur la base d'une représentation bow des documents avec la méthode des k-moyennes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLADoE6qXRIw"
      },
      "source": [
        "Le partitionnement en [**k-moyennes** (ou _k-means_ en anglais)](https://fr.wikipedia.org/wiki/K-moyennes) est une des méthodes de partitionnement les plus populaires. \n",
        "> Étant donnés des points et un entier k, le problème est de diviser les points en k groupes, souvent appelés clusters, de façon à minimiser une certaine fonction. On considère la distance d'un point à la moyenne des points de son cluster ; la fonction à minimiser est la somme des carrés de ces distances. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx8NSC9WXkVK"
      },
      "source": [
        "Ci-dessus, les processus de vectorisation vous ont conduit à avoir 2 matrices document-terms : \n",
        "- dans la première, `c_matrix`, les termes sont représentés par leur nombre d'occurrences\n",
        "- dans la seconde, `tfidf_matrix`, par un score tf-idf \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fu0kUpgYkly"
      },
      "source": [
        "#### QUESTION\n",
        "\n",
        "Ci-dessous un code qui réalise un clustering kmeans sur une matrice document-term donnée en entrée, à savoir la matrice `c_matrix`.\n",
        "Le nombre de catégories étant connu (3), il est spécifié en paramètre (`n_clusters=3`).\n",
        "\n",
        "* Dupliquez le code et modifiez le pour considérer comme input,`dt_matrix`, au clustering kmeans, la matrice document-term `tfidf_matrix`. Pour chacune des deux représentations (`c_matrix` et `tfidf_matrix`), en regardant le `ClusterLabel` produit, pouvez-dire que le clustering produit est correct ? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "LeFj5jXaUeDu",
        "outputId": "7138ef65-a425-4daf-cda4-9fada7effac4"
      },
      "source": [
        "dt_matrix = c_matrix \n",
        "\n",
        "# clustering des documents selon la méthode kmeans \n",
        "from sklearn.cluster import KMeans\n",
        "km = KMeans(n_clusters=3, random_state=0)\n",
        "km.fit_transform(dt_matrix)\n",
        "\n",
        "# affichage des clusters\n",
        "cluster_labels = km.labels_\n",
        "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])\n",
        "pd.concat([corpus_df, cluster_labels], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Category</th>\n",
              "      <th>ClusterLabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The sky is blue and beautiful.</td>\n",
              "      <td>weather</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this blue and beautiful sky!</td>\n",
              "      <td>weather</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
              "      <td>animals</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
              "      <td>food</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
              "      <td>food</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
              "      <td>animals</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
              "      <td>weather</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The dog is lazy but the brown fox is quick!</td>\n",
              "      <td>animals</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                             Document  ... ClusterLabel\n",
              "0                                      The sky is blue and beautiful.  ...            2\n",
              "1                                   Love this blue and beautiful sky!  ...            2\n",
              "2                        The quick brown fox jumps over the lazy dog.  ...            1\n",
              "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans  ...            0\n",
              "4                         I love green eggs, ham, sausages and bacon!  ...            0\n",
              "5                    The brown fox is quick and the blue dog is lazy!  ...            1\n",
              "6            The sky is very blue and the sky is very beautiful today  ...            2\n",
              "7                         The dog is lazy but the brown fox is quick!  ...            1\n",
              "\n",
              "[8 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpEnQFHrap4Z"
      },
      "source": [
        "#### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubj7O7wAcnqr"
      },
      "source": [
        "#TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecXXZGnUfEOz"
      },
      "source": [
        "## Similarité entre documents \n",
        "\n",
        "Une représentation vectorielle des documents offre la possibilité d'utiliser des mesures de distance ou de similarité pour comparer les documents un à un.\n",
        "\n",
        "Si le corpus compte C documents, une comparaison de chaque paire de documents produira une matrice de dimensions C x C où chaque intersection d'une ligne et d'une colonne donne un score de similarité entre une paire de documents.\n",
        "\n",
        "Parmi les mesures les plus communes on retrouve la similarité cosinus, la distance euclidienne, la distance manhattan, la similarité BM25, la distance Jaccard...\n",
        "\n",
        "Ci-dessous nous utilisons la mesure de cosinus sur une modélisation TF-IDF des documents. La mesure de cosinus représente la valeur du cosinus de l'angle entre les vecteurs de deux documents. Moins l'angle entre les vecteurs est grand, plus proches et similaires sont les documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyhlqukAjJ0E"
      },
      "source": [
        "### QUESTION\n",
        "\n",
        "Le code ci-dessous permet de calculer la matrice de similarité entre paires de documents. \n",
        "* En analysant la matrice, quels ensembles de documents vous semblent similaires ? A minima vérifier votre intuition à la lecture des documents du corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcIUjd53fCQA"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity_matrix = cosine_similarity(tfidf_matrix)\n",
        "similarity_df = pd.DataFrame(similarity_matrix)\n",
        "similarity_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGO_LIxfjCgb"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "**TODO**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmQ5roGcmKWV"
      },
      "source": [
        "##Partitionnement hiérarchique des documents sur la base de la matrice de similarités inter-documents \n",
        "\n",
        "Le [**partitionnement**, ou _Clustering_ en anglais,](https://fr.wikipedia.org/wiki/Partitionnement_de_donn%C3%A9es) désigne des techniques non supervisées qui permettent de grouper des points (ici des documents) en groupes ou clusters.\n",
        "\n",
        "Il existe deux types d'algorithmes de partionnement hiérarchique : agglomératif ou clivant.\n",
        "\n",
        "Nous utiliserons un algorithme hiérarchique de clustering agglomératif qui débutera avec 1 document dans chaque cluster et aggrégera deux clusters à chaque itération. Nous utiserons le [critère de liaison de Ward ](https://fr.wikipedia.org/wiki/M%C3%A9thode_de_Ward) pour choisir des paires de clusters à lier. \n",
        "> La méthode de Ward consiste à regrouper les classes de façon que l'augmentation de l'inertie interclasse soit maximale, ou, de façon que l'augmentation de l'inertie intraclasse (la variance intra-cluster) soit minimale.\n",
        "\n",
        "Le code ci-dessous produit la matrice de liaison (_linkage_). Chaque ligne représente une étape qui indique quels points (clusters) sont fusionnés ensembles. Les deux premières colonnes indiquent les identifiants des clusters fusionnés, la troisième colonne est la distance entre les deux clusters fusionnés, et la quatrième colonne indique le nombre total d'éléments ainsi regroupés.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aznwkc_P2Iwu"
      },
      "source": [
        "from scipy.cluster.hierarchy import linkage\n",
        "\n",
        "Z = linkage(similarity_matrix, 'ward')\n",
        "pd.DataFrame(Z, columns=['Document\\Cluster 1', 'Document\\Cluster 2', \n",
        "                         'Distance', 'Cluster Size'], dtype='object')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blxzfWvy2MrS"
      },
      "source": [
        "La construction de cette matrice peut est visualisée sous la forme d'un dendogramme. La ligne en pointillée représente la valeur maximale de distance à partir de laquelle il ne faut plus chercher à regrouper. Elle est arbitrairement fixée ici à `0.1`. On remarque qu'avec cette valeur, on obtient autant de clusters que de documents dans le corpus. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bZORtA53dcY"
      },
      "source": [
        "from scipy.cluster.hierarchy import dendrogram\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# seuil maximale pour la mesure de distance \n",
        "max_dist = 0.1\n",
        "\n",
        "# plot the dendogram\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plt.xlabel('Data point')\n",
        "plt.ylabel('Distance')\n",
        "dendrogram(Z)\n",
        "\n",
        "# plot the threshold (seuil de distance)\n",
        "plt.axhline(y=max_dist, c='k', ls='--', lw=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQwfVg2H8Clg"
      },
      "source": [
        "### QUESTION\n",
        "\n",
        "Le code ci-dessous vous permet de stopper le clustering à un seuil maximal de distance préfixé.\n",
        "\n",
        "* En jouant avec la valeur de la distance maximale, y-a-t'il moyen d'identifier nos principaux clusters ? Si oui autour de quelle valeur ?  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBLmGVtz6KNK"
      },
      "source": [
        "max_dist = 0.1\n",
        "\n",
        "# Flatten clusters from the hierarchical clustering defined by the given linkage matrix\n",
        "from scipy.cluster.hierarchy import fcluster\n",
        "cluster_labels = fcluster(Z, max_dist, criterion='distance')\n",
        "\n",
        "# Concaténation de la colonne des labels des clusters avec le corpus et les catégories manuelles \n",
        "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])\n",
        "pd.concat([corpus_df, cluster_labels], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3LWq-fx2JYn"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "**TODO**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA5jFb1I5fRm"
      },
      "source": [
        "## Partitionnement des documents sur la base de la matrice de similarités inter-documents avec la méthode des k-moyennes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5FWFDnzW9lf"
      },
      "source": [
        "La matrice de similarités cosinus inter-documents peut être vue comme matrice _document-similarity_score_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IVKYzTP_ngg"
      },
      "source": [
        "### QUESTION\n",
        "\n",
        "* En regardant le `ClusterLabel` produit, pouvez-vous dire si la catégorisation est correcte ? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaUsj4Qc98FE"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# clusetering\n",
        "km = KMeans(n_clusters=3, random_state=0)\n",
        "km.fit_transform(similarity_matrix)\n",
        "\n",
        "# affichage\n",
        "cluster_labels = km.labels_\n",
        "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])\n",
        "pd.concat([corpus_df, cluster_labels], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi-TMeTX_a-3"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "**TODO**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKta7IOqFAZN"
      },
      "source": [
        "# Topic modeling with LDA's gensim \n",
        "L'[**allocation de Dirichlet latente** (de l'anglais _Latent Dirichlet Allocation_) ou LDA](https://fr.wikipedia.org/wiki/Allocation_de_Dirichlet_latente) est ...\n",
        "> ... un modèle génératif probabiliste permettant d'expliquer des ensembles d’observations, par le moyen de groupes non observés, eux-mêmes définis par des similarités de données. \n",
        "\n",
        "Dans ce modèle chaque document consiste en une combinaison de plusieurs thèmes et chaque terme peut être assigné (avec une certaine probabilité) à un certain thème. \n",
        "L'algorithme est itératif. \n",
        "- Initialement les thèmes sont assignés aléatoirement à chaque terme pour chaque document. \n",
        "- Puis pendant un nombre d'itération prédéfini, on répète pour chaque document :  \n",
        "  - calculer `P(T|D)`, la probabilité du thème `T` donné la proportion de termes associés à ce thème `T` dans le document `D` \n",
        "  - calculer `P(W|T)`, la probabilité d'assigner le thème `T` au terme `W` donné la proportion de thèmes `T` assignés au terme `W` dans le corpus\n",
        "  - réassigner le terme `W` au thème `T` avec la probabilité  `P(T|D)*P(W|T)`\n",
        "\n",
        "\n",
        "Pour en savoir plus consulter le [tutoriel de Christine Doig](http://chdoig.github.io/pygotham-topic-modeling/) \n",
        "\n",
        "Les modules [gensim](https://radimrehurek.com/gensim/models/ldamodel.html) et [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html) offrent des implémentations de l'algorithme LDA pour générer des topiques. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aHntHjvPLV0"
      },
      "source": [
        "### QUESTION\n",
        "\n",
        "Ci-dessous nous mettons en oeuvre le module gensim qui offre une API de haut niveau. Le paramètre \"important\" est le nombre de thèmes (`num_topics=3 \n",
        "`) souhaités en fin de processus. En connaissance du corpus, nous le fixons à 3.\n",
        "\n",
        "La méthode `ldamodel.show_topics()` affiche les thèmes et les poids associés à chaque terme pour chaque thème. Plus le poid est élevé plus le terme est significatif pour ce thème.\n",
        "* Observez les résultats retournés par la méthode `ldamodel.show_topics()`, les poids vous semblent-ils cohérents ? \n",
        "* Relancer plusieurs fois la modélisation. Vous pouvez aussi utiliser le module PyLDAvis pour visualiser le topic model généré (cf. ci-dessous).  La modélisation est-elle stable ? Pourquoi ? Spécifier les paramètres suivants `iterations=10000, random_state=1234` dans la classe `LdaModel`. Le modèle est-il plus stable ? \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E5bXGBBFM3_"
      },
      "source": [
        "from gensim.models import LdaModel\n",
        "from gensim import corpora\n",
        "\n",
        "# récupérer une version normalisé du corpus\n",
        "preprocessed_corpus = tfidf_vectorizer.inverse_transform(tfidf_matrix)\n",
        "\n",
        "# build a dictionary\n",
        "dictionary = corpora.Dictionary(preprocessed_corpus)\n",
        "# and a doc2bow gensim corpus\n",
        "# doc2bow Convert document into the bag-of-words (BoW) format = list of (token_id, token_count) tuples.\n",
        "doc2bow_corpus = [dictionary.doc2bow(document) for document in preprocessed_corpus]\n",
        "print (doc2bow_corpus)\n",
        "\n",
        "# then compute a topic model with topics based on gensim LDA\n",
        "num_topics=3 \n",
        "ldamodel = LdaModel(doc2bow_corpus, id2word=dictionary, num_topics=num_topics)\n",
        "\n",
        "# Get a representation for selected topics\n",
        "ldamodel.show_topics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EASbsMEcFRQK"
      },
      "source": [
        " Vous pouvez aussi utiliser le module PyLDAvis pour visualiser le topic model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9771TUjvFWNs"
      },
      "source": [
        "!pip install pyLDAvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYDxaTzSFaQQ"
      },
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "# feed the LDA model into the pyLDAvis instance\n",
        "lda_display = gensimvis.prepare(ldamodel, doc2bow_corpus, dictionary, mds='mmds')\n",
        "#print (lda_display)\n",
        "pyLDAvis.display(lda_display)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptJmSAyDRriw"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ3eI6o_fq6A"
      },
      "source": [
        "## Partitionnement des documents sur la base de la matrice document-topic avec la méthode des k-moyennes\n",
        "\n",
        "Il s'agit de lancer un clustering k-means des documents non plus sur une représentation des documents en termes d'un sac de mots pondérés avec un score TF-IDF mais d'utiliser la distribution des thèmes générés par l'algorithme LDA sur chaque document.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cMigh2khY-m"
      },
      "source": [
        "### QUESTION\n",
        "\n",
        "Le code suivant permet de faire un partitionnement des documents en 3 groupes  sur la base d'une représentation des documents à base des thèmes qui les composent. Pour chaque document les thèmes ont un score de probabilité différent. Ce nombre 3 correpond au nombre de catégories de documents que nous connaissons être présentes dans ce corpus.\n",
        "\n",
        "* En utilisant le code de la section précédente (Topic modeling with LDA's gensim) pour générer des modèles de thèmes, générer des modèles avec différents nombre de thèmes générés : 3, 8 ou 10 par exemples. Cela va conduire à représenter chaque document avec 3, 8 ou 10 thèmes par exemples.\n",
        "Avec combien de thèmes dans la représentation des documents, obtenez-vous le meilleur clustering ? Les vecteurs des thèmes ont-ils toujours un sens pour vous ? Que pouvez-vous dire de cette représentation par rapport à la représentation BOW qui avait pour dimension le vocabulaire ? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMjP8BD-gT9e"
      },
      "source": [
        "# Récupère une matrice de distribution des thèmes pour chaque document\n",
        "dt_matrix = ldamodel.get_document_topics(doc2bow_corpus)\n",
        "\n",
        "# sklearn.cluster.KMeans utilise une matrice des scores alors que la matrice \n",
        "# retournée par gensim contient des tuples (topic_id, score) \n",
        "# le code suivant fait la conversion de format\n",
        "new_dt_matrix = list()\n",
        "for d in dt_matrix:\n",
        "  new_dt_matrix.append([c for i, c in d])\n",
        "print (new_dt_matrix)\n",
        "dt_matrix = new_dt_matrix\n",
        "\n",
        "# visualisation de la distribution des thèmes sur chaque document ; ici dans le cas où il y a 3 thèmes\n",
        "#features = pd.DataFrame(dt_matrix, columns=['T1', 'T2', 'T3'])\n",
        "#features\n",
        "\n",
        "# clustering des documents selon la méthode kmeans \n",
        "# en utilisant la distribution des thèmes et non la distrubution des termes \n",
        "# comme traits discriminants entre documents\n",
        "from sklearn.cluster import KMeans\n",
        "# Warning: ici n_clusters ne doit pas être touché\n",
        "km = KMeans(n_clusters=3, random_state=0)\n",
        "#km.fit_transform(features)\n",
        "km.fit_transform(dt_matrix)\n",
        "\n",
        "# affichage des clusters\n",
        "cluster_labels = km.labels_\n",
        "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])\n",
        "pd.concat([corpus_df, cluster_labels], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY4OMNakilOO"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "**TODO**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFBKM65tIoK8"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "On retiendra que les vectorisations des documents sous la forme d'un sac de mots d'un vocabulaire permet d'obtenir des résultats intéressants en recherche d'information et en partitionnement mais présente deux défauts :\n",
        "\n",
        "- un modèle \"sac de mots\" ne conserve pas l'ordre des mots et leur contexte d'apparition des mots\n",
        "- les vecteurs sont de grande taille, celle du vocabulaire du corpus. Quitte à être remplis de valeurs nulles.\n",
        "\n",
        "La représentation d'un document à travers des thèmes globalement générés sur le corpus constitue une représentation plus compacte qu'une représentation avec un vocabulaire comme trait. La matrice de documents est au final non creuse.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjvyEFwqcgp1"
      },
      "source": [
        "# Références\n",
        "* https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
        "* word2vec embeddings building, most similar and visualization (ENSAE 2021) https://colab.research.google.com/drive/1Y9fC04hnTspwmqJkK5yZJWwUpDybzq9m#scrollTo=Uy2u0Ngs1R-w\n",
        "* traditional and Words embeddings avec Word2vec https://github.com/clement-plancq/outils-corpus/blob/master/outils_corpus-7.ipynb\n",
        "* text preprocessing, Bag of Words Model, Bag of N-Grams Model, TF-IDF Model, Document Similarity, Document Clustering with Similarity Features, Topic Models, Document Clustering with Topic Model Features\n",
        "  * https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41\n",
        "  *  Traditional strategies (2020)  https://github.com/dipanjanS/text-analytics-with-python/blob/master/New-Second-Edition/Ch04%20-%20Feature%20Engineering%20for%20Text%20Representation/Ch04a%20-%20Feature%20Engineering%20Text%20Data%20-%20Traditional%20Strategies.ipynb\n",
        "  * With some explanation https://github.com/dipanjanS/nlp_essentials/blob/master/notebooks/02_Text_Representation_Statistical_Models.ipynb\n",
        "  * Advanced Deep Learning Strategies (2020) https://github.com/dipanjanS/text-analytics-with-python/blob/master/New-Second-Edition/Ch04%20-%20Feature%20Engineering%20for%20Text%20Representation/Ch04b%20-%20Feature%20Engineering%20Text%20Data%20-%20Advanced%20Deep%20Learning%20Strategies.ipynb\n",
        "  * Older version 2018  https://github.com/dipanjanS/practical-machine-learning-with-python/blob/master/notebooks/Ch04_Feature_Engineering_and_Selection/Feature%20Engineering%20on%20Text%20Data.ipynb ; https://github.com/dipanjanS/practical-machine-learning-with-python/blob/master/notebooks/Ch04_Feature_Engineering_and_Selection/Feature%20Engineering%20on%20Text%20Data.ipynb\n",
        "* https://github.com/fastai/course-nlp/blob/master/2-svd-nmf-topic-modeling.ipynb\n",
        "* https://github.com/dipanjanS/nlp_essentials/blob/master/notebooks/04_NLP_Applications_Text_Similarity_Content_Recommenders.ipynb\n",
        "* topic modelling with Gensim's LDA and visualization with PyLDAvis (ENSAE 2021)  https://colab.research.google.com/drive/1-4OAfhAZGWNzTB1CAtIEPvK-xJ6SunnP?usp=sharing#scrollTo=F2BCX2wSt9VA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pour aller plus loin\n"
      ],
      "metadata": {
        "id": "wp7AXsuUm5zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il s'agit maintenant de jouer avec un jeu de données de taille plus grande, d'observer les limites physiques (temps de traitement, mémoire...) et d'expérimenter librement l'impact de pré-traitements (et normalisations) linguistiques (via `spacy, ``sklearn` ou autre) et des types de vectorisation (`Binary`, `Count`, `TF-IDF`, `Topic-based`) sur une tâche de clustering.\n",
        "\n",
        "Idéalement les cellules suivantes devraient s'exécuter mais malheureusement elles rencontrent quelques limites physiques... A vous de jouer sur la représentation du corpus pour obtenir des résultats. Un indice : après avoir constaté que la limite physique que rencontre l'étape 3 (clustering), commencez par réduire le nombre de dimensions utilisés pour décrire un document.\n",
        "\n",
        "Les cellules suivantes couvrent les étapes \n",
        "- 1. collecte et aperçu du jeu de données \n",
        "- 2. pré-traitement et vectorisation des documents\n",
        "- 3. clustering\n",
        "- 4. évaluation du clustering\n",
        "\n",
        "Votre travail concerne l'étape 2.\n",
        "\n",
        "\n",
        "## Collecte et aperçu des données\n",
        "\n",
        "Ici il n'y a rien à modifier."
      ],
      "metadata": {
        "id": "yUIjjXK8AO5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.options.display.max_colwidth = 200\n",
        "import numpy as np\n",
        "\n",
        "# The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics \n",
        "# split in one training and one testing subsets.\n",
        "# In the following work we will focus on the training subset and select some topics. \n",
        "# https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        " \n",
        "topic_selection =  ['alt.atheism',\n",
        " 'comp.os.ms-windows.misc', 'comp.sys.mac.hardware',\n",
        " 'rec.autos',  'rec.motorcycles',\n",
        " 'sci.space',  'sci.med',\n",
        " 'soc.religion.christian',\n",
        " 'talk.politics.guns', 'talk.politics.mideast'\n",
        "]\n",
        "dataset = fetch_20newsgroups(subset='train', categories=topic_selection, shuffle=True, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# A look at the fetched dataset \n",
        "# print the labels\n",
        "print (len(list(dataset.target_names)), list(dataset.target_names))\n",
        "# check the number of labels\n",
        "print (len(dataset.target))\n",
        "# check the number of documents\n",
        "print (len(dataset.data))\n",
        "# see the first document \n",
        "print (dataset['data'][0])\n",
        "\n",
        "# For visualization purpose, build the dataset as a dataframe with a document \n",
        "# and its corresponding topic per line\n",
        "corpus_df = pd.DataFrame({'Document': dataset.data, 'Topic': dataset.target})\n",
        "corpus_df = corpus_df[['Document', 'Topic']]\n",
        "# show the data with label 8 i.e. the 8th labels in `topic_selection``: 'talk.politics.guns'\n",
        "corpus_df.loc[corpus_df['Topic'] == 8]\n",
        "\n",
        "# Processing the documents (linguistic processing, text normalization and vectorization...) \n",
        "corpus = np.array(dataset.data)"
      ],
      "metadata": {
        "id": "IYLtUtslnDLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac2d95d-03ae-407f-c8cc-35c5f4afdb63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 ['alt.atheism', 'comp.os.ms-windows.misc', 'comp.sys.mac.hardware', 'rec.autos', 'rec.motorcycles', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast']\n",
            "5737\n",
            "5737\n",
            "Does anybody have any solid data on how many legally owned versus\n",
            "illegally owned firearms are used in crime.  I know the number of\n",
            "legally owned guns used in crime is small, but I would like a number,\n",
            "and a reference if possible.\n",
            "\n",
            "Data should be e-mailed to me.\n",
            "Open discussion should be directed to talk.politics.guns\n",
            "\n",
            "-Seth\n",
            "\n",
            "__________________________________________________________________________\n",
            "[unlike cats] dogs NEVER scratch you when you wash them. They just\n",
            "become very sad and try to figure out what they did wrong. -Dave Barry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prétraitement et vectorisation \n",
        "\n",
        "C'est ici que vous devez intervenir à la fois pour \n",
        "- exploiter au maximum les limites physiques de votre environnement sans le faire tomber \n",
        "- affiner le modèle afin d'augmenter la qualité du clustering"
      ],
      "metadata": {
        "id": "--Fx-McQnQ7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO free to preprocess if you like\n",
        "# ...\n",
        "\n",
        "# define the vectorizer\n",
        "# TODO free to change and experiment your own vectorizer and parameters\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "\n",
        "# display the configuration of the vectorizer\n",
        "print (vectorizer)\n",
        "\n",
        "# perform the vectorization\n",
        "vectorized_document_matrix = vectorizer.fit_transform(corpus)\n",
        "print ('Matrix dimensions:', vectorized_document_matrix.get_shape())\n",
        "\n",
        "# get all unique words in the corpus (the vocabulary and also the names of the matrix columns/features)\n",
        "vocab = vectorizer.get_feature_names()\n",
        "print ('Vocabulary size:', len(vocab))\n",
        "\n",
        "# show document-term matrix\n",
        "vectorized_document_matrix = vectorized_document_matrix.toarray()\n",
        "pd.DataFrame(vectorized_document_matrix, columns=vocab)"
      ],
      "metadata": {
        "id": "v9XPQf4snKjJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "3f14efbe-1e14-4034-aaff-eff9c4a153d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer(stop_words='english')\n",
            "Matrix dimensions: (5737, 76224)\n",
            "Vocabulary size: 76224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      00  000  0000  00000  000000  0000000004  000062david42  0001  00014  \\\n",
              "0      0    0     0      0       0           0              0     0      0   \n",
              "1      0    0     0      0       0           0              0     0      0   \n",
              "2      0    0     0      0       0           0              0     0      0   \n",
              "3      0    0     0      0       0           0              0     0      0   \n",
              "4      0    0     0      0       0           0              0     0      0   \n",
              "...   ..  ...   ...    ...     ...         ...            ...   ...    ...   \n",
              "5732   0    0     0      0       0           0              0     0      0   \n",
              "5733   0    0     0      0       0           0              0     0      0   \n",
              "5734   0    0     0      0       0           0              0     0      0   \n",
              "5735   0    0     0      0       0           0              0     0      0   \n",
              "5736   0    0     0      0       0           0              0     0      0   \n",
              "\n",
              "      000152  ...  zzneu  zznki  zznkj  zznkjz  zznkzz  zznp  zzrk  zzy_3w  \\\n",
              "0          0  ...      0      0      0       0       0     0     0       0   \n",
              "1          0  ...      0      0      0       0       0     0     0       0   \n",
              "2          0  ...      0      0      0       0       0     0     0       0   \n",
              "3          0  ...      0      0      0       0       0     0     0       0   \n",
              "4          0  ...      0      0      0       0       0     0     0       0   \n",
              "...      ...  ...    ...    ...    ...     ...     ...   ...   ...     ...   \n",
              "5732       0  ...      0      0      0       0       0     0     0       0   \n",
              "5733       0  ...      0      0      0       0       0     0     0       0   \n",
              "5734       0  ...      0      0      0       0       0     0     0       0   \n",
              "5735       0  ...      0      0      0       0       0     0     0       0   \n",
              "5736       0  ...      0      0      0       0       0     0     0       0   \n",
              "\n",
              "      zzz  zzzoh  \n",
              "0       0      0  \n",
              "1       0      0  \n",
              "2       0      0  \n",
              "3       0      0  \n",
              "4       0      0  \n",
              "...   ...    ...  \n",
              "5732    0      0  \n",
              "5733    0      0  \n",
              "5734    0      0  \n",
              "5735    0      0  \n",
              "5736    0      0  \n",
              "\n",
              "[5737 rows x 76224 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10d197d4-2810-4205-95cc-9854850a68de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>0000</th>\n",
              "      <th>00000</th>\n",
              "      <th>000000</th>\n",
              "      <th>0000000004</th>\n",
              "      <th>000062david42</th>\n",
              "      <th>0001</th>\n",
              "      <th>00014</th>\n",
              "      <th>000152</th>\n",
              "      <th>...</th>\n",
              "      <th>zzneu</th>\n",
              "      <th>zznki</th>\n",
              "      <th>zznkj</th>\n",
              "      <th>zznkjz</th>\n",
              "      <th>zznkzz</th>\n",
              "      <th>zznp</th>\n",
              "      <th>zzrk</th>\n",
              "      <th>zzy_3w</th>\n",
              "      <th>zzz</th>\n",
              "      <th>zzzoh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5732</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5734</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5735</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5736</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5737 rows × 76224 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10d197d4-2810-4205-95cc-9854850a68de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10d197d4-2810-4205-95cc-9854850a68de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10d197d4-2810-4205-95cc-9854850a68de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering\n",
        "\n",
        "Ici il n'y a rien à modifier."
      ],
      "metadata": {
        "id": "SSZKwISZA8qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cluster documents with kmeans \n",
        "from sklearn.cluster import KMeans\n",
        "km = KMeans(n_clusters=9, random_state=1234)\n",
        "km.fit_transform(vectorized_document_matrix)\n",
        "\n",
        "# show the predicted clusters\n",
        "cluster_labels = km.labels_\n",
        "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])\n",
        "pd.concat([corpus_df, cluster_labels], axis=1)"
      ],
      "metadata": {
        "id": "blgMwsmlA8aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Measure the performance of the clustering\n",
        "\n",
        "Pour évaluer les performances d'un système de clustering, différentes [métriques de mesures de _clustering_](https://towardsdatascience.com/performance-metrics-in-machine-learning-part-3-clustering-d69550662dc6)  sont disponibles. Nous en utilisons deux ici : \n",
        "* **[rand index](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.rand_score.html?highlight=rand_score#sklearn.metrics.rand_score)**: computes a similarity measure between two clusterings by considering all pairs of samples and counting pairs that are assigned in the same or different clusters in the predicted and true clusterings. \n",
        "* Une version dite **[ajustée](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score)** \n",
        "\n",
        "Dans les deux cas un score qui se rapproche de 1.0 signifie que la prédiction du clustering est proche de la classification de référence.\n",
        "\n"
      ],
      "metadata": {
        "id": "29Ra_ZTrnZMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import rand_score, adjusted_mutual_info_score\n",
        "\n",
        "labels_true = dataset.target\n",
        "labels_pred = [e[0] for e in cluster_labels.values.tolist()]\n",
        "\n",
        "#\n",
        "print ('rand index:', rand_score(labels_true, labels_pred))\n",
        "print ('adjusted rand index:', adjusted_mutual_info_score(labels_true, labels_pred))"
      ],
      "metadata": {
        "id": "WMtbZBi1nZWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rapport d'expérience\n",
        "\n",
        "Faire un retour sur l'expérience de traitement d'un jeu de données de taille réelle. Discuter des représentations, de l'impact sur les ressources physiques, et de la qualité du clustering."
      ],
      "metadata": {
        "id": "Bh3e-eZJgQr3"
      }
    }
  ]
}